insert into mldatasource (connectiondetails, description, dshashcode, name, organization, salt, type, category, activetime, lastmodifiedby, lastmodifieddate, alias, extras, interfacetype) values('{"NoProxy":"false","bucketName":"aicloudprd","formats":{"bucketName":"input","datasource-dp":"Datasource","projectId-dp":"Project Id","deployId-dp":"Deployment-Id","deployId":"input","userId":"input","userId-dp":"AICloud UserID","modId":"input","storageUri-dp":"StorageUri","endId":"input","storageType-dp":"Storage Type","modelversion-dp":"Mod-Version","datasource":"datasourceDropdown","modId-dp":"Model-Id","scope":"input","scope-dp":"Scope","endId-dp":"Endpoint-Id","storageUri":"input","storageType":"input","bucketName-dp":"Bucket Name","projectId":"input","modelversion":"input"},"ConnectionType":"ApiRequest","AuthDetails":{"password":"","authParams":{"grant_type":"","client_secret":"","client_id":""},"authToken":""},"userId":"leapAccount01@infosys.com","deployId":"","Url":"https://api-aicloud.ad.infosys.com","tokenExpirationTime":"","datasource":"AIPNTNXH56520","scope":"Private","testDataset":{"name":"","attributes":{"bodyType":"raw","Endpoint":"","RequestMethod":"GET","Headers":"","LeapParams":[],"QueryParams":"","Body":""}},"storageType":"INFY_AICLD_NUTANIX","AuthType":"token","projectId":"5a663746b15c40f3bf923f6ca835d62a","fileId":""}','',NULL,'AIPACLDT26697','leo1311',NULL,'AICLOUD','REST','2023-09-01 10:29:48','Shreya_Bansal@ad.infosys.com','2023-09-01 10:29:48','AICLOUD','{"apispec":{},"apispectemplate":{}}',NULL);
            insert into mldatasource (connectiondetails, description, dshashcode, name, organization, salt, type, category, activetime, lastmodifiedby, lastmodifieddate, alias, extras, interfacetype) values('{"secretKey":"g2d4nVxehagjOkCkZ4WrCMOzrfTrFiI0","accessKey":"GISeSU7xd6WBnXrU-QbffBee7WsCxaE2","Region":"us-east-1","url":"https://10.82.53.110"}','',NULL,'AIPNTNXH56520','leo1311',NULL,'S3','S3','2023-07-24 06:49:14','admin','2023-07-24 06:49:15','Nutanix','{"apispec":{},"apispectemplate":{}}',NULL);
            insert into mldatasource (connectiondetails, description, dshashcode, name, organization, salt, type, category, activetime, lastmodifiedby, lastmodifieddate, alias, extras, interfacetype, fordataset, foradapter, forruntime, formodel) values('{"NoProxy":"true","formats":{"datasource-dp":"Datasource","bucketname-dp":"Bucket Name","storageType-dp":"Storage Type","datasource":"datasourceDropdown","bucketname":"input","projectId-dp":"Project Id","storageType":"input","projectId":"input","userId":"input","userId-dp":"User Id"},"ConnectionType":"ApiRequest","AuthDetails":{"authParams":{"grant_type":"","client_secret":"","client_id":""}},"userId":"leapAccount01@infosys.com","Url":"https://victlpth5-04.ad.infosys.com:8092/execute","tokenExpirationTime":"","datasource":"AIPNTNXH56520","bucketname":"aiplatdev","testDataset":{"name":"","attributes":{"bodyType":"raw","Endpoint":"","RequestMethod":"GET","Headers":"","LeapParams":[],"QueryParams":"","Body":""}},"storageType":"s3","AuthType":"NoAuth","projectId":"Demo","fileId":""}','',NULL,'LEALCLCL12132','leo1311',NULL,'REMOTE','REST',NULL,'poornasai.nagendra@ad.infosys.com','2023-07-26 09:59:32','LocalCluster','{"apispec":{},"apispectemplate":{}}',NULL,'0','0','1','0');
			insert into mldatasource (connectiondetails, description, dshashcode, name, organization, salt, type, category, activetime, lastmodifiedby, lastmodifieddate, alias, extras, interfacetype, fordataset, foradapter, forruntime, formodel) values ('{"NoProxy":"true","formats":{"datasource-dp":"Datasource","bucketname-dp":"Bucket Name","storageType-dp":"Storage Type","datasource":"datasourceDropdown","bucketname":"input","projectId-dp":"Project Id","storageType":"input","projectId":"input","userId":"input","userId-dp":"User Id"},"ConnectionType":"ApiRequest","AuthDetails":{"authParams":{"grant_type":"","client_secret":"","client_id":""}},"Url":"http://10.66.15.100:30415/execute","tokenExpirationTime":"","datasource":"AIPNTNXH56520","bucketname":"aiplatdev","testDataset":{"name":"","attributes":{"Endpoint":"","RequestMethod":"GET","Headers":"","LeapParams":[],"QueryParams":"","Body":""}},"storageType":"s3","AuthType":"NoAuth","projectId":"leo1311","fileId":""}','',NULL,'LEOSPRKJ56521','leo1311',NULL,'REMOTE','REST',NULL,'admin','2024-08-08 09:04:08','SparkJobExecuter','{"apispec":{},"apispectemplate":{}}',NULL,'0','0','1','0');
            UPDATE mldataset SET views='Table View' WHERE datasource IN(SELECT NAME FROM mldatasource WHERE TYPE='MYSQL');
            UPDATE mldataset SET views='Table View' WHERE datasource IN(SELECT NAME FROM mldatasource WHERE TYPE='MSSQL');
            UPDATE mldataset SET views='JSON View' WHERE datasource IN(SELECT NAME FROM mldatasource WHERE TYPE='REST');
            insert into mldatasource (connectiondetails, description, dshashcode, name, organization, salt, type, category, activetime, lastmodifiedby, lastmodifieddate, alias, extras, interfacetype) values('{"password":"enc8bu9aaBiPC/BkfAw2QIdsnDdwGz88KSIp1zeqg==","userName":"leapadmin","url":"jdbc:mysql://CVICTLPTST2:3306/aifirst"}','','fd495caf16e0c4bd92812e6983781ce0bcf55b2ab9c4037f9250012dc0cf28fe','AIPAFRST27144','leo1311','dP8SexDRX2vvsvfKcNvXTB+qFcj/9i7xBWNVA5NC46HVHZ9PeSbGn6iH8yULxKwHBqGimU8VuabP96Vho5iSNw==','MYSQL','SQL','2023-09-01 10:54:02','Shreya_Bansal@ad.infosys.com','2023-09-01 10:54:02','aifirst','{"apispec":{},"apispectemplate":{}}',NULL);
            insert into mldataset (attributes, dataset_type, description, exp_status, name, organization, schemajson, type, backing_dataset, dataset_schema, datasource, lastmodifiedby, lastmodifieddate, alias, context, is_approval_required, is_permission_managed, is_inbox_required, is_audit_required, is_archival_enabled, archival_config, dashboard, metadata, modeltype, views, taskdetails, tags, interfacetype, adaptername, isadapteractive) values('{"filter":"","mode":"query","Query":"select * from codegen_result","Cacheable":false,"isStreaming":"false","Headers":"","defaultValues":"","QueryParams":"","writeMode":"append","params":"{}","tableName":"codegen_result","uniqueIdentifier":""}',NULL,'Results of codegen 350m model','0','AIPCDGN365739','leo1311',NULL,'r',NULL,NULL,'AIPAFRST27144','admin','2023-07-28 09:35:24','CodeGen 350m Result',NULL,'','','','',NULL,NULL,NULL,NULL,NULL,'Table View','[]','[]',NULL,NULL,NULL);
            insert into mldataset (attributes, dataset_type, description, exp_status, name, organization, schemajson, type, backing_dataset, dataset_schema, datasource, lastmodifiedby, lastmodifieddate, alias, context, is_approval_required, is_permission_managed, is_inbox_required, is_audit_required, is_archival_enabled, archival_config, dashboard, metadata, modeltype, views, taskdetails, tags, interfacetype, adaptername, isadapteractive) values('{"filter":"","mode":"query","Query":"select * from codegen_infer","Cacheable":false,"isStreaming":"false","Headers":"","defaultValues":"","QueryParams":"","writeMode":"append","params":"{}","tableName":"codegen_infer","uniqueIdentifier":""}',NULL,'Codegen 350m test dataset','0','AIPCDGN319613','leo1311',NULL,'r',NULL,NULL,'AIPAFRST27144','admin','2023-07-28 09:34:53','CodeGen 350m Test',NULL,'','','','',NULL,NULL,NULL,NULL,NULL,'Table View','[]','[]',NULL,NULL,NULL);
            insert into mldataset (attributes, dataset_type, description, exp_status, name, organization, schemajson, type, backing_dataset, dataset_schema, datasource, lastmodifiedby, lastmodifieddate, alias, context, is_approval_required, is_permission_managed, is_inbox_required, is_audit_required, is_archival_enabled, archival_config, dashboard, metadata, modeltype, views, taskdetails, tags, interfacetype, adaptername, isadapteractive) values('{"filter":"","mode":"query","Query":"select * from plBart_trainSet limit 100","Cacheable":false,"isStreaming":"false","Headers":"","defaultValues":"","QueryParams":"","writeMode":"append","params":"{}","tableName":"","uniqueIdentifier":""}',NULL,'Dataset to train code generation models','0','AIPCDGN-35473','leo1311',NULL,'r',NULL,NULL,'AIPAFRST27144','Shreya_Bansal@ad.infosys.com','2023-09-01 10:44:46','CodeGen-350m Train',NULL,'','','','',NULL,NULL,NULL,NULL,NULL,'Table View','[]','[]',NULL,NULL,NULL);
            delete from mlfederatedmodels where app_org='leo1311';
            insert into mlfederatedmodels (fed_id,app_name,fed_name, adapter_id, status, raw_payload, artifacts, container, app_description, fed_description, version, created_on, created_by, sync_date, app_modified_date, fed_modified_date, fed_modified_by, app_modified_by, app_org, fed_org, is_deleted, model_type, model_likes, model_metadata, adapter_alias, app_status, model_deployment) values ('041c53504d0d560230fd4fe9','stablediffusion','stablediffusion','AIPACLDT26697','Deployed','{"container":{"args":["string"],"imageUri":"infyartifactory.jfrog.io/ainadel-mms-project-customized/stablediffusion-1-4:v1.1","healthProbeUri":"string","envVariables":[{"name":"string","value":"string"}],"ports":[{"name":"http","value":"5006"}],"command":["string"],"labels":[{"name":"framework","value":"PyTorch"}]},"metadata":{"modelParameters":{"data":[{"name":"StableDiffusion","link":"https://huggingface.co/CompVis/stable-diffusion-v1-4","sensitive":[{"Fields":[""]}],"classification":"Public"}],"outputFormatMap":[{"value":"Gives the generated Json from the model","key":"predictedBase64Image"}],"modelArchitecture":"","inputFormat":"Json","inputFormatMap":[{"value":"prompt","key":"input_text"},{"value":"Number of images you need","key":"num_images"}],"outputFormat":"Json"},"modelDetails":{"overview":"Diffusion-based text-to-image generation model. This model is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input.","path":"https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/main","licenses":[{"identifier":"CreativeML OpenRAIL M license","customText":"https://bigscience.huggingface.co/blog/the-bigscience-rail-license"}],"tasktype":"Text-to-Image","customTags":[{"tags":"Diffusers"}],"citations":[{"citation":"https://arxiv.org/abs/2112.10752","style":"Journal Paper"}],"references":[{"reference":"https://huggingface.co/CompVis/stable-diffusion-v1-4"}],"versionHistory":[{"date":"2023-06-08T10:59:20.194000","name":"","diff":""}],"displayName":"StableDiffusion","documentation":"https://huggingface.co/CompVis/stable-diffusion-v1-4","owners":[{"contact":"https://huggingface.co/","name":"CompVis"}]},"quantitativeAnalysis":{"performanceMetrics":[{"confidenceInterval":{"upperBound":"","lowerBound":""},"slice":"","type":"","value":""}]},"considerations":{"useCases":[{"description":"Image generation"}],"tradeoffs":[{"description":""}],"ethicalConsiderations":[{"name":"","mitigationStrategy":""}],"environmentalConsiderations":[{"hoursUsed":"150000","cloudProvider":"AWS","hardwareType":"A100 PCIe 40GB","carbonEmitted":"11250 kg CO2 eq.","computeRegion":"US-east"}],"users":[{"description":""}],"limitations":[{"description":"The model does not perform well on more difficult tasks which involve compositionality, such as rendering an image corresponding to \u201cA red cube on top of a blue sphere\u201d, The model does not achieve perfect photorealism, Faces and people in general may not be generated properly."}]}},"updatedBy":null,"description":"Stable Diffusion is is a latent text-to-image diffusion model which is primarily used to generate detailed images conditioned on text descriptions. This can be used for designing logos, creation of animation and visual effects in motion pictures and tasks such as inpainting, outpainting,etc. Training Data: LAION''s high resolution dataset, a subset of LAION-5b, having 170 million pictures with a resolution of more than 1024 × 1024 pixels. Downsized later to 512 × 512 due to efficiency results.","createdOn":"2023-05-17T11:02:24.732000","version":1,"modifiedOn":"2023-05-17T11:02:24.732000","isDeleted":false,"createdBy":"s_reka@infosys.com","name":"stablediffusion","id":"041c53504d0d560230fd4fe9","projectId":"5a663746b15c40f3bf923f6ca835d62a","artifacts":{"storageType":"INFY_AICLD_NUTANIX","uri":"s3://aicloudprd/foundational_model/stablediffusion"},"status":"Deployed"}','{"storageType":"INFY_AICLD_NUTANIX","uri":"s3://aicloudprd/foundational_model/stablediffusion"}','{"args":["string"],"imageUri":"infyartifactory.jfrog.io/ainadel-mms-project-customized/stablediffusion-1-4:v1.1","healthProbeUri":"string","envVariables":[{"name":"string","value":"string"}],"ports":[{"name":"http","value":"5006"}],"command":["string"],"labels":[{"name":"framework","value":"PyTorch"}]}','Stable Diffusion is is a latent text-to-image diffusion model which is primarily used to generate detailed images conditioned on text descriptions. This can be used for designing logos, creation of animation and visual effects in motion pictures and tasks such as inpainting, outpainting,etc. Training Data: LAION\''s high resolution dataset, a subset of LAION-5b, having 170 million pictures with a resolution of more than 1024 × 1024 pixels. Downsized later to 512 × 512 due to efficiency results.','Stable Diffusion is is a latent text-to-image diffusion model which is primarily used to generate detailed images conditioned on text descriptions. This can be used for designing logos, creation of animation and visual effects in motion pictures and tasks such as inpainting, outpainting,etc. Training Data: LAION\''s high resolution dataset, a subset of LAION-5b, having 170 million pictures with a resolution of more than 1024 × 1024 pixels. Downsized later to 512 × 512 due to efficiency results.','1','2023-05-17 11:14:36','s_reka@infosys.com','2023-09-01 10:34:01',NULL,'2023-05-17 11:14:36','null',NULL,'leo1311','5a663746b15c40f3bf923f6ca835d62a','','AICLOUD','0',NULL,'AICLOUD','Deployed',NULL);
            insert into mlfederatedmodels (fed_id, app_name, fed_name, adapter_id, status, raw_payload, artifacts, container, app_description, fed_description, version, created_on, created_by, sync_date, app_modified_date, fed_modified_date, fed_modified_by, app_modified_by, app_org, fed_org, is_deleted, model_type, model_likes, model_metadata, adapter_alias, app_status, model_deployment) values('479a49ffb9a7bb54be2e398c','codegen','codegen','AIPACLDT26697','Deployed','{"container":{"args":["string"],"imageUri":"infyartifactory.jfrog.io/ainadel-mms-project-customized/nvd-tritonserver:22.08-py3","healthProbeUri":"string","envVariables":[{"name":"string","value":"string"}],"ports":[{"name":"http","value":"8000"}],"command":["string"],"labels":[{"name":"framework","value":"PyTorch"}]},"metadata":{"modelParameters":{"data":[{"name":"Codegen-2B-multi","link":"https://huggingface.co/Salesforce/codegen-2B-multi","sensitive":[{"Fields":[""]}],"classification":"Public"}],"outputFormatMap":[{"value":"Gives the generated Json from the model","key":"outputs"}],"modelArchitecture":"","inputFormat":"Json","inputFormatMap":[{"value":"prompt","key":"inputs"}],"outputFormat":"Json"},"modelDetails":{"overview":"CodeGen is a family of autoregressive language models for program synthesis from the paper: A Conversational Paradigm for Program Synthesis by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong. The models are originally released in this repository, under 3 pre-training data variants (NL, Multi, Mono) and 4 model size variants (350M, 2B, 6B, 16B).","path":"https://huggingface.co/Salesforce/codegen-2B-multi/tree/main","licenses":[{"identifier":"","customText":""}],"tasktype":"Text Generation","customTags":[{"tags":"codegen"}],"citations":[{"citation":"https://arxiv.org/abs/2203.13474","style":"Journal Paper"}],"references":[{"reference":"https://huggingface.co/Salesforce/codegen-2B-multi"}],"versionHistory":[{"date":"2023-06-08T10:59:20.194000","name":"","diff":""}],"displayName":"Codegen-2B-multi","documentation":"https://huggingface.co/Salesforce/codegen-2B-multi","owners":[{"contact":"https://huggingface.co/","name":"Salesforce"}]},"quantitativeAnalysis":{"performanceMetrics":[{"confidenceInterval":{"upperBound":"","lowerBound":""},"slice":"","type":"","value":""}]},"considerations":{"useCases":[{"description":"Code Generation"}],"tradeoffs":[{"description":""}],"ethicalConsiderations":[{"name":"","mitigationStrategy":""}],"environmentalConsiderations":[{"hoursUsed":"","cloudProvider":"","hardwareType":"","carbonEmitted":"","computeRegion":""}],"users":[{"description":""}],"limitations":[{"description":""}]}},"updatedBy":null,"description":"Salesforce codegen-2b-multi language model fine tuned with Java code from IS repo in Infosys Github. Training Data: Java code from IS repo in Infosys GitHub (52K+ files, 225MB) and output from customized IS code gen tool.IS Java code deployed in production follows IS quality, security and performance standards. De-duplication is taken care by using only the latest version of the production code for fine tuning. Java code is transformed into appropriate JSON format to fine tune the model. The access to fine tuning data is controlled.","createdOn":"2023-05-17T11:00:06.173000","version":1,"modifiedOn":"2023-05-17T11:00:06.173000","isDeleted":false,"createdBy":"s_reka@infosys.com","name":"codegen","id":"479a49ffb9a7bb54be2e398c","projectId":"5a663746b15c40f3bf923f6ca835d62a","artifacts":{"storageType":"INFY_AICLD_NUTANIX","uri":"s3://aicloudprd/triton_codegn/base_models"},"status":"Deployed"}','{"storageType":"INFY_AICLD_NUTANIX","uri":"s3://aicloudprd/triton_codegn/base_models"}','{"args":["string"],"imageUri":"infyartifactory.jfrog.io/ainadel-mms-project-customized/nvd-tritonserver:22.08-py3","healthProbeUri":"string","envVariables":[{"name":"string","value":"string"}],"ports":[{"name":"http","value":"8000"}],"command":["string"],"labels":[{"name":"framework","value":"PyTorch"}]}','Salesforce codegen-2b-multi language model fine tuned with Java code from IS repo in Infosys Github. Training Data: Java code from IS repo in Infosys GitHub (52K+ files, 225MB) and output from customized IS code gen tool.IS Java code deployed in production follows IS quality, security and performance standards. De-duplication is taken care by using only the latest version of the production code for fine tuning. Java code is transformed into appropriate JSON format to fine tune the model. The access to fine tuning data is controlled.','Salesforce codegen-2b-multi language model fine tuned with Java code from IS repo in Infosys Github. Training Data: Java code from IS repo in Infosys GitHub (52K+ files, 225MB) and output from customized IS code gen tool.IS Java code deployed in production follows IS quality, security and performance standards. De-duplication is taken care by using only the latest version of the production code for fine tuning. Java code is transformed into appropriate JSON format to fine tune the model. The access to fine tuning data is controlled.','1','2023-05-17 11:02:59','s_reka@infosys.com','2023-09-01 10:34:01',NULL,'2023-05-17 11:02:59','null',NULL,'leo1311','5a663746b15c40f3bf923f6ca835d62a','','AICLOUD','0',NULL,'AICLOUD','Deployed',NULL);
            insert into mlfederatedmodels (fed_id, app_name, fed_name, adapter_id, status, raw_payload, artifacts, container, app_description, fed_description, version, created_on, created_by, sync_date, app_modified_date, fed_modified_date, fed_modified_by, app_modified_by, app_org, fed_org, is_deleted, model_type, model_likes, model_metadata, adapter_alias, app_status, model_deployment) values('6f54644cc21a1bb22f9930e3','whisper-m','whisper-m','AIPACLDT26697','Deployed','{"container":{"args":null,"imageUri":"infyartifactory.jfrog.io/ainadel-mms-project-customized/nvd-pytorch-1-11-0-whisper-medium-infer:v1.0","healthProbeUri":null,"envVariables":[{"name":"string","value":"string"}],"ports":[{"name":"http","value":"5000"}],"command":null,"labels":[{"name":"framework","value":"Flask"}]},"metadata":{"modelParameters":{"data":[{"name":"Whisper-m","link":"https://huggingface.co/openai/whisper-medium","sensitive":[{"Fields":[""]}],"classification":"Public"}],"outputFormatMap":[{"value":"Gives the generated Json from the model","key":"text"}],"modelArchitecture":"Transformer based encoder-decoder model","inputFormat":"Json","inputFormatMap":[{"value":"prompt of base64 encoded audio","key":"audio_bytes"}],"outputFormat":"Json"},"modelDetails":{"overview":"Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning.","path":"https://huggingface.co/openai/whisper-medium/tree/main","licenses":[{"identifier":"","customText":""}],"tasktype":"Automatic Speech Recognition","customTags":[{"tags":"whisper, Speech-to-Text"}],"citations":[{"citation":"https://arxiv.org/abs/2212.04356","style":"Journal Paper"}],"references":[{"reference":"https://huggingface.co/openai/whisper-medium"}],"versionHistory":[{"date":"2023-06-08T10:59:20.194000","name":"","diff":""}],"displayName":"Whisper-m","documentation":"https://huggingface.co/openai/whisper-medium","owners":[{"contact":"https://huggingface.co/","name":"openai"}]},"quantitativeAnalysis":{"performanceMetrics":[{"confidenceInterval":{"upperBound":"","lowerBound":""},"slice":"","type":"","value":""}]},"considerations":{"useCases":[{"description":"Speech-to-Text"}],"tradeoffs":[{"description":""}],"ethicalConsiderations":[{"name":"","mitigationStrategy":""}],"environmentalConsiderations":[{"hoursUsed":"","cloudProvider":"","hardwareType":"","carbonEmitted":"","computeRegion":""}],"users":[{"description":""}],"limitations":[{"description":""}]}},"updatedBy":null,"description":"Open-source pre-trained Whisper-M model for speech-to-text conversion. Training Data: Trained on 680,000 hours of audio and the corresponding transcripts collected from the internet. 65% of this data (or 438,000 hours) represents English-language audio and matched English transcripts, roughly 18% (or 126,000 hours) represents non-English audio and English transcripts, while the final 17% (or 117,000 hours) represents non-English audio and the corresponding transcript. This non-English data represents 98 different languages.","createdOn":"2023-05-23T06:11:56.766000","version":1,"modifiedOn":"2023-05-23T06:11:56.766000","isDeleted":false,"createdBy":"s_reka@infosys.com","name":"whisper-m","id":"6f54644cc21a1bb22f9930e3","projectId":"5a663746b15c40f3bf923f6ca835d62a","artifacts":{"storageType":"INFY_AICLD_NUTANIX","uri":"s3://aicloudprd/foundational_model/whisper/medium"},"status":"Deployed"}','{"storageType":"INFY_AICLD_NUTANIX","uri":"s3://aicloudprd/foundational_model/whisper/medium"}','{"args":null,"imageUri":"infyartifactory.jfrog.io/ainadel-mms-project-customized/nvd-pytorch-1-11-0-whisper-medium-infer:v1.0","healthProbeUri":null,"envVariables":[{"name":"string","value":"string"}],"ports":[{"name":"http","value":"5000"}],"command":null,"labels":[{"name":"framework","value":"Flask"}]}','Open-source pre-trained Whisper-M model for speech-to-text conversion. Training Data: Trained on 680,000 hours of audio and the corresponding transcripts collected from the internet. 65% of this data (or 438,000 hours) represents English-language audio and matched English transcripts, roughly 18% (or 126,000 hours) represents non-English audio and English transcripts, while the final 17% (or 117,000 hours) represents non-English audio and the corresponding transcript. This non-English data represents 98 different languages.','Open-source pre-trained Whisper-M model for speech-to-text conversion. Training Data: Trained on 680,000 hours of audio and the corresponding transcripts collected from the internet. 65% of this data (or 438,000 hours) represents English-language audio and matched English transcripts, roughly 18% (or 126,000 hours) represents non-English audio and English transcripts, while the final 17% (or 117,000 hours) represents non-English audio and the corresponding transcript. This non-English data represents 98 different languages.','1','2023-05-23 06:24:42','s_reka@infosys.com','2023-09-01 10:34:01',NULL,'2023-05-23 06:24:42','null',NULL,'leo1311','5a663746b15c40f3bf923f6ca835d62a','','AICLOUD','0',NULL,'AICLOUD','Deployed',NULL);
            insert into mlfederatedmodels (fed_id, app_name, fed_name, adapter_id, status, raw_payload, artifacts, container, app_description, fed_description, version, created_on, created_by, sync_date, app_modified_date, fed_modified_date, fed_modified_by, app_modified_by, app_org, fed_org, is_deleted, model_type, model_likes, model_metadata, adapter_alias, app_status, model_deployment) values('6f54644cc21a1bb22f9930e5','starcoderbase','starcoderbase','AIPACLDT26697','Deployed','{"container":{"args":null,"imageUri":"infyartifactory.jfrog.io/docker-local/starcoderbase:v1.0.0","healthProbeUri":null,"envVariables":[],"ports":[{"name":"http","value":"8080"}],"command":null,"labels":[{"name":"framework","value":"Flask"}]},"metadata":{"modelParameters":{"data":[{"name":"starcoderbase","link":"https://huggingface.co/bigcode/starcoderbase","sensitive":[{"Fields":[""]}],"classification":"Public"}],"outputFormatMap":[{"value":"Gives the generated Json from the model","key":"generated_text"}],"modelArchitecture":"Transformer based encoder-decoder model","inputFormat":"Json","inputFormatMap":[{"value":"prompt","key":"input"}],"outputFormat":"Json"},"modelDetails":{"overview":"The StarCoderBase models are 15.5B parameter models trained on 80+ programming languages from The Stack (v1.2), with opt-out requests excluded. The model uses Multi Query Attention, a context window of 8192 tokens, and was trained using the Fill-in-the-Middle objective on 1 trillion tokens.","path":"https://huggingface.co/bigcode/starcoderbase","licenses":[{"identifier":"","customText":""}],"tasktype":"Text Generation","customTags":[{"tags":"text-generation"}],"citations":[{"citation":"","style":""}],"references":[{"reference":"https://huggingface.co/bigcode/starcoderbase"}],"versionHistory":[{"date":"2023-06-08T10:59:20.194000","name":"","diff":""}],"displayName":"starcoderbase","documentation":"https://huggingface.co/bigcode/starcoderbase","owners":[{"contact":"https://huggingface.co/","name":"openai"}]},"quantitativeAnalysis":{"performanceMetrics":[{"confidenceInterval":{"upperBound":"","lowerBound":""},"slice":"","type":"","value":""}]},"considerations":{"useCases":[{"description":"text generation"}],"tradeoffs":[{"description":""}],"ethicalConsiderations":[{"name":"","mitigationStrategy":""}],"environmentalConsiderations":[{"hoursUsed":"","cloudProvider":"","hardwareType":"","carbonEmitted":"","computeRegion":""}],"users":[{"description":""}],"limitations":[{"description":""}]}},"updatedBy":null,"description":"The StarCoderBase models are 15.5B parameter models trained on 80+ programming languages from The Stack (v1.2), with opt-out requests excluded. The model uses Multi Query Attention, a context window of 8192 tokens, and was trained using the Fill-in-the-Middle objective on 1 trillion tokens.","createdOn":"2023-08-29T06:11:56.766000","version":1,"modifiedOn":"2023-08-29T06:11:56.766000","isDeleted":false,"createdBy":"leapAccount01@infosys.com","name":"starcoderbase","id":"6f54644cc21a1bb22f9930e5","projectId":"5a663746b15c40f3bf923f6ca835d62a","artifacts":{"storageType":"INFY_AICLD_NUTANIX","uri":"s3://aicloudprd/foundational_model/starcoder/bigcode/starcoderbase"},"status":"Deployed"}','{"storageType":"INFY_AICLD_NUTANIX","uri":"s3://aicloudprd/foundational_model/starcoder/bigcode/starcoderbase"}','{"args":null,"imageUri":"infyartifactory.jfrog.io/docker-local/starcoderbase:v1.0.0","healthProbeUri":null,"envVariables":[],"ports":[{"name":"http","value":"8080"}],"command":null,"labels":[{"name":"framework","value":"Flask"}]}','The StarCoderBase models are 15.5B parameter models trained on 80+ programming languages from The Stack (v1.2), with opt-out requests excluded. The model uses Multi Query Attention, a context window of 8192 tokens, and was trained using the Fill-in-the-Middle objective on 1 trillion tokens.','The StarCoderBase models are 15.5B parameter models trained on 80+ programming languages from The Stack (v1.2), with opt-out requests excluded. The model uses Multi Query Attention, a context window of 8192 tokens, and was trained using the Fill-in-the-Middle objective on 1 trillion tokens.','1','2023-08-29 06:24:42','leapAccount01@infosys.com','2023-09-01 10:34:01',NULL,'2023-08-29 06:24:42','null',NULL,'leo1311','5a663746b15c40f3bf923f6ca835d62a','','AICLOUD','0',NULL,'AICLOUD','Deployed',NULL);
            insert into mlfederatedmodels (fed_id, app_name, fed_name, adapter_id, status, raw_payload, artifacts, container, app_description, fed_description, version, created_on, created_by, sync_date, app_modified_date, fed_modified_date, fed_modified_by, app_modified_by, app_org, fed_org, is_deleted, model_type, model_likes, model_metadata, adapter_alias, app_status, model_deployment) values('c569cd233e96eb694a1f1c2c','bloom7b1','bloom7b1','AIPACLDT26697','Deployed','{"container":{"args":null,"imageUri":"infyartifactory.jfrog.io/ainadel-mms-project-customized/bloom7b:version1.0","healthProbeUri":null,"envVariables":[{"name":"string","value":"string"}],"ports":[{"name":"http","value":"5001"}],"command":null,"labels":[{"name":"framework","value":"Flask"}]},"metadata":{"modelParameters":{"data":[{"name":"Bloom7b1","link":"https://huggingface.co/bigscience/bloom#training-data","sensitive":[{"Fields":[""]}],"classification":"Public"}],"outputFormatMap":[{"value":"Gives the generated Json from the model","key":"generated_text"}],"modelArchitecture":"Decoder-only architecture","inputFormat":"Json","inputFormatMap":[{"value":"prompt","key":"inputs"},{"value":"A Dict a following keys min_length, max_new_tokens, temperature, no_repeat_ngram_size","key":"parameters"}],"outputFormat":"Json"},"modelDetails":{"overview":"BigScience Large Open-science Open-access Multilingual Language Model","path":"https://huggingface.co/bigscience/bloom-7b1/tree/main","licenses":[{"identifier":"RAIL License v1.0","customText":"https://huggingface.co/spaces/bigscience/license"}],"tasktype":"Text Generation","customTags":[{"tags":"bloom"}],"citations":[{"citation":"https://arxiv.org/abs/2211.05100","style":"Journal Paper"}],"references":[{"reference":"https://huggingface.co/bigscience/bloom-7b1"}],"versionHistory":[{"date":"2022-07-11T10:59:20.194000","name":"1.0.0","diff":""}],"displayName":"Bloom7b1","documentation":"https://huggingface.co/bigscience/bloom-7b1","owners":[{"contact":"https://huggingface.co/","name":"bigscience"}]},"quantitativeAnalysis":{"performanceMetrics":[{"confidenceInterval":{"upperBound":"","lowerBound":""},"slice":"","type":"Training Loss","value":"2.3"},{"confidenceInterval":{"upperBound":"","lowerBound":""},"slice":"","type":"Validation Loss","value":"2.9"},{"confidenceInterval":{"upperBound":"","lowerBound":""},"slice":"","type":"Perplexity","value":"16"}]},"considerations":{"useCases":[{"description":"Content Authoring"}],"tradeoffs":[{"description":""}],"ethicalConsiderations":[{"name":"","mitigationStrategy":""}],"environmentalConsiderations":[{"hoursUsed":"","cloudProvider":"","hardwareType":"","carbonEmitted":"","computeRegion":""}],"users":[{"description":"Infosys ETA"}],"limitations":[{"description":"Make errors, including producing incorrect information as if it were factual, Generate irrelevant or repetitive outputs, Generate irrelevant or repetitive outputs"}]}},"updatedBy":null,"description":"BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based large language model for Language generation and content authoring. Training Data: 46 natural languages and 13 programming languages. In total, 1.6 TeraByte pre-processed text was converted into 350 billion unique tokens as BLOOM''s training datasets.","createdOn":"2023-05-18T07:31:19.030000","version":1,"modifiedOn":"2023-05-18T07:31:19.030000","isDeleted":false,"createdBy":"s_reka@infosys.com","name":"bloom7b1","id":"c569cd233e96eb694a1f1c2c","projectId":"5a663746b15c40f3bf923f6ca835d62a","artifacts":{"storageType":"INFY_AICLD_NUTANIX","uri":"s3://aicloudprd/foundational_model/bloom/bloom-7b1"},"status":"Deployed"}','{"storageType":"INFY_AICLD_NUTANIX","uri":"s3://aicloudprd/foundational_model/bloom/bloom-7b1"}','{"args":null,"imageUri":"infyartifactory.jfrog.io/ainadel-mms-project-customized/bloom7b:version1.0","healthProbeUri":null,"envVariables":[{"name":"string","value":"string"}],"ports":[{"name":"http","value":"5001"}],"command":null,"labels":[{"name":"framework","value":"Flask"}]}','BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based large language model for Language generation and content authoring. Training Data: 46 natural languages and 13 programming languages. In total, 1.6 TeraByte pre-processed text was converted into 350 billion unique tokens as BLOOM''s training datasets.','BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based large language model for Language generation and content authoring. Training Data: 46 natural languages and 13 programming languages. In total, 1.6 TeraByte pre-processed text was converted into 350 billion unique tokens as BLOOM''s training datasets.','1','2023-05-18 07:31:49','s_reka@infosys.com','2023-09-01 10:34:01',NULL,'2023-05-18 07:31:49','null',NULL,'leo1311','5a663746b15c40f3bf923f6ca835d62a','','AICLOUD','0',NULL,'AICLOUD','Deployed',NULL);
            insert into mlfederatedmodels (fed_id, app_name, fed_name, adapter_id, status, raw_payload, artifacts, container, app_description, fed_description, version, created_on, created_by, sync_date, app_modified_date, fed_modified_date, fed_modified_by, app_modified_by, app_org, fed_org, is_deleted, model_type, model_likes, model_metadata, adapter_alias, app_status, model_deployment) values('f0c46ef4b4322ffcd03dab52','flant5-xl','flant5-xl','AIPACLDT26697','Deployed','{"container":{"args":null,"imageUri":"deepjavalibrary/djl-serving:0.20.0-deepspeed","healthProbeUri":null,"envVariables":[{"name":"string","value":"string"}],"ports":[{"name":"http","value":"8080"}],"command":null,"labels":[{"name":"framework","value":"PyTorch"}]},"metadata":{"modelParameters":{"data":[{"name":"Flant5-xl","link":"https://huggingface.co/google/flan-t5-xl","sensitive":[{"Fields":[""]}],"classification":"Public"}],"outputFormatMap":[{"value":"Gives the generated Json from the model","key":"generated_text"}],"modelArchitecture":"","inputFormat":"Json","inputFormatMap":[{"value":"prompt","key":"inputs"},{"value":"A Dict a following key: max_length","key":"parameters"}],"outputFormat":"Json"},"modelDetails":{"overview":"Flan-T5 is fine-tuned on a large corpus of text data that was not filtered for explicit content or assessed for existing biases. Training Data: Flan collection of datasets which include: taskmaster2, djaym7/wiki_dialog, deepmind/code_contests, lambada, gsm8k, aqua_rat, esnli, quasc and qed.","path":"https://huggingface.co/google/flan-t5-xl/tree/main","licenses":[{"identifier":"Apache 2.0","customText":""}],"tasktype":"Text2text Generation","customTags":[{"tags":"flant5"}],"citations":[{"citation":"https://arxiv.org/pdf/2210.11416.pdf","style":"Journal Paper"}],"references":[{"reference":"https://huggingface.co/google/flan-t5-xl"}],"versionHistory":[{"date":"2023-06-08T10:59:20.194000","name":"","diff":""}],"displayName":"Flant5-xl","documentation":"https://huggingface.co/google/flan-t5-xl","owners":[{"contact":"","name":"google"}]},"quantitativeAnalysis":{"performanceMetrics":[{"confidenceInterval":{"upperBound":"","lowerBound":""},"slice":"","type":"","value":""}]},"considerations":{"useCases":[{"description":"Text generation"}],"tradeoffs":[{"description":""}],"ethicalConsiderations":[{"name":"","mitigationStrategy":""}],"environmentalConsiderations":[{"hoursUsed":"","cloudProvider":"GCP","hardwareType":"Google Cloud TPU Pods - TPU v3 or TPU v4 | Number of chips ≥ 4.","carbonEmitted":"","computeRegion":""}],"users":[{"description":""}],"limitations":[{"description":"Flan-T5 has not been tested in real world applications, Flan-T5 should not be applied for any unacceptable use cases, e.g., generation of abusive speech."}]}},"updatedBy":null,"description":"Flan-T5 is fine-tuned on a large corpus of text data that was not filtered for explicit content or assessed for existing biases. Training Data: Flan collection of datasets which include: taskmaster2, djaym7/wiki_dialog, deepmind/code_contests, lambada, gsm8k, aqua_rat, esnli, quasc and qed.","createdOn":"2023-05-18T08:27:33.209000","version":1,"modifiedOn":"2023-05-18T08:27:33.209000","isDeleted":false,"createdBy":"s_reka@infosys.com","name":"flant5-xl","id":"f0c46ef4b4322ffcd03dab52","projectId":"5a663746b15c40f3bf923f6ca835d62a","artifacts":{"storageType":"INFY_AICLD_NUTANIX","uri":"s3://aicloudprd/foundational_model/flant5/google/xl"},"status":"Deployed"}','{"storageType":"INFY_AICLD_NUTANIX","uri":"s3://aicloudprd/foundational_model/flant5/google/xl"}','{"args":null,"imageUri":"deepjavalibrary/djl-serving:0.20.0-deepspeed","healthProbeUri":null,"envVariables":[{"name":"string","value":"string"}],"ports":[{"name":"http","value":"8080"}],"command":null,"labels":[{"name":"framework","value":"PyTorch"}]}','Flan-T5 is fine-tuned on a large corpus of text data that was not filtered for explicit content or assessed for existing biases. Training Data: Flan collection of datasets which include: taskmaster2, djaym7/wiki_dialog, deepmind/code_contests, lambada, gsm8k, aqua_rat, esnli, quasc and qed.','Flan-T5 is fine-tuned on a large corpus of text data that was not filtered for explicit content or assessed for existing biases. Training Data: Flan collection of datasets which include: taskmaster2, djaym7/wiki_dialog, deepmind/code_contests, lambada, gsm8k, aqua_rat, esnli, quasc and qed.','1','2023-05-18 08:31:02','s_reka@infosys.com','2023-09-01 10:34:01',NULL,'2023-05-18 08:31:02','null',NULL,'leo1311','5a663746b15c40f3bf923f6ca835d62a','','AICLOUD','0',NULL,'AICLOUD','Deployed',NULL);
            delete from mlfederatedendpoints where app_org='leo1311';
            insert into mlfederatedendpoints (fed_id, adapter_id, app_name, fed_name, fed_org, app_org, status, deployed_models, adapter_alias, created_by, created_on, is_deleted, app_modified_by, fed_modified_by, app_modified_date, fed_modified_date, sync_date, endpoint_type, endpoint_likes, endpoint_metadata, raw_payload, context_uri, app_application, app_sample, app_status, app_description) values('0e6b3c08862110bc11d45b77','AIPACLDT26697','stablediffusion','stablediffusion','5a663746b15c40f3bf923f6ca835d62a','leo1311','Created','[{"modelId":"041c53504d0d560230fd4fe9","deploymentId":"e316db2c5bf73c0ec6e602d2","endpointUri":["https://api-aicloud.ad.infosys.com/v1/vision/generate/models/stablediffusion/versions/1/infer"],"version":1}]','AICLOUD','s_reka@infosys.com','2023-05-17 12:39:46','','','null','2023-09-07 10:24:21','2023-05-17 12:39:46','2023-05-17 12:39:46','AICLOUD','0',NULL,'{"modifiedOn":"2023-05-17T12:32:35.431000","updatedBy":null,"isDeleted":false,"createdBy":"s_reka@infosys.com","name":"stablediffusion","id":"0e6b3c08862110bc11d45b77","contextUri":"/vision","createdOn":"2023-05-17T12:32:35.431000","projectId":"5a663746b15c40f3bf923f6ca835d62a","deployedModels":[{"modelId":"041c53504d0d560230fd4fe9","deploymentId":"e316db2c5bf73c0ec6e602d2","endpointUri":["https://api-aicloud.ad.infosys.com/v1/vision/generate/models/stablediffusion/versions/1/infer"],"version":1}],"status":"Created"}','/vision','https://victlpth5-04:7877/','','Mapped','endpoint description');            
            insert into mlfederatedendpoints (fed_id, adapter_id, app_name, fed_name, fed_org, app_org, status, deployed_models, adapter_alias, created_by, created_on, is_deleted, app_modified_by, fed_modified_by, app_modified_date, fed_modified_date, sync_date, endpoint_type, endpoint_likes, endpoint_metadata, raw_payload, context_uri, app_application, app_sample, app_status, app_description) values('330744580e8407000807493e','AIPACLDT26697','codegen','codegen','5a663746b15c40f3bf923f6ca835d62a','leo1311','Created','[{"modelId":"479a49ffb9a7bb54be2e398c","deploymentId":"e316db2c5bf73c0ec6e602d1","endpointUri":["https://api-aicloud.ad.infosys.com/v1/code/complete/models/codegen/versions/1/infer"],"version":1}]','AICLOUD','s_reka@infosys.com','2023-05-17 12:14:59','','','null','2023-09-01 10:50:19','2023-05-17 12:14:59','2023-05-17 12:14:59','AICLOUD','0',NULL,'{"modifiedOn":"2023-05-17T12:11:40.199000","updatedBy":null,"isDeleted":false,"createdBy":"s_reka@infosys.com","name":"codegen","id":"330744580e8407000807493e","contextUri":"/code","createdOn":"2023-05-17T12:11:40.199000","projectId":"5a663746b15c40f3bf923f6ca835d62a","deployedModels":[{"modelId":"479a49ffb9a7bb54be2e398c","deploymentId":"e316db2c5bf73c0ec6e602d1","endpointUri":["https://api-aicloud.ad.infosys.com/v1/code/complete/models/codegen/versions/1/infer"],"version":1}],"status":"Created"}','/code','https://victlpth5-04:7874/','','Mapped','endpoint description');            
            insert into mlfederatedendpoints (fed_id, adapter_id, app_name, fed_name, fed_org, app_org, status, deployed_models, adapter_alias, created_by, created_on, is_deleted, app_modified_by, fed_modified_by, app_modified_date, fed_modified_date, sync_date, endpoint_type, endpoint_likes, endpoint_metadata, raw_payload, context_uri, app_application, app_sample, app_status, app_description) values('40f6fcbf80d479943782d669','AIPACLDT26697','bloom','bloom','5a663746b15c40f3bf923f6ca835d62a','leo1311','Created','[{"modelId":"c569cd233e96eb694a1f1c2c","deploymentId":"e316db2c5bf73c0ec6e602d4","endpointUri":["https://api-aicloud.ad.infosys.com/v1/language/generate/models/bloom7b1/versions/1/infer"],"version":1},{"modelId":"f0c46ef4b4322ffcd03dab52","deploymentId":"e316db2c5bf73c0ec6e602d5","endpointUri":["https://api-aicloud.ad.infosys.com/v1/language/generate/models/flant5-xl/versions/1/infer"],"version":1}]','AICLOUD','s_reka@infosys.com','2023-05-18 07:49:56','','','null','2023-09-01 10:51:38','2023-05-18 07:49:56','2023-05-18 07:49:56','AICLOUD','0',NULL,'{"modifiedOn":"2023-05-18T07:34:13.943000","updatedBy":null,"isDeleted":false,"createdBy":"s_reka@infosys.com","name":"bloom","id":"40f6fcbf80d479943782d669","contextUri":"/language","createdOn":"2023-05-18T07:34:13.943000","projectId":"5a663746b15c40f3bf923f6ca835d62a","deployedModels":[{"modelId":"c569cd233e96eb694a1f1c2c","deploymentId":"e316db2c5bf73c0ec6e602d4","endpointUri":["https://api-aicloud.ad.infosys.com/v1/language/generate/models/bloom7b1/versions/1/infer"],"version":1},{"modelId":"f0c46ef4b4322ffcd03dab52","deploymentId":"e316db2c5bf73c0ec6e602d5","endpointUri":["https://api-aicloud.ad.infosys.com/v1/language/generate/models/flant5-xl/versions/1/infer"],"version":1}],"status":"Created"}','/language','https://victlpth5-04:7878/','','Mapped','endpoint description');
            insert into mlfederatedendpoints (fed_id, adapter_id, app_name, fed_name, fed_org, app_org, status, deployed_models, adapter_alias, created_by, created_on, is_deleted, app_modified_by, fed_modified_by, app_modified_date, fed_modified_date, sync_date, endpoint_type, endpoint_likes, endpoint_metadata, raw_payload, context_uri, app_application, app_sample, app_status, app_description) values('54e198f2faf3e9f1463aa77a','AIPACLDT26697','codegentestseptendpoint','codegentestseptendpoint','5a663746b15c40f3bf923f6ca835d62a','leo1311','Created','[{"modelId":"078487545f11f7a55acebbba","deploymentId":"5d0735646043c81b4a12af10","endpointUri":["https://api-aicloud.ad.infosys.com/v1/codegen350m/codegen/models/codegentestseptsixth/versions/1/infer"],"version":1}]','AICLOUD','leapAccount01@infosys.com','2023-09-06 18:43:26','',NULL,'null',NULL,'2023-09-06 18:43:26','2023-09-06 18:43:26','AICLOUD','0',NULL,'{"modifiedOn":"2023-09-06T18:38:38.288000","updatedBy":null,"isDeleted":false,"createdBy":"leapAccount01@infosys.com","name":"codegentestseptendpoint","id":"54e198f2faf3e9f1463aa77a","contextUri":"/codegen350m","createdOn":"2023-09-06T18:38:38.288000","projectId":"5a663746b15c40f3bf923f6ca835d62a","deployedModels":[{"modelId":"078487545f11f7a55acebbba","deploymentId":"5d0735646043c81b4a12af10","endpointUri":["https://api-aicloud.ad.infosys.com/v1/codegen350m/codegen/models/codegentestseptsixth/versions/1/infer"],"version":1}],"status":"Created"}','/codegen350m',NULL,NULL,'Mapped','endpoint description');
            insert into mlfederatedendpoints (fed_id, adapter_id, app_name, fed_name, fed_org, app_org, status, deployed_models, adapter_alias, created_by, created_on, is_deleted, app_modified_by, fed_modified_by, app_modified_date, fed_modified_date, sync_date, endpoint_type, endpoint_likes, endpoint_metadata, raw_payload, context_uri, app_application, app_sample, app_status, app_description) values('6f684c9584f74717dbb34d84','AIPACLDT26697','whisper','whisper','5a663746b15c40f3bf923f6ca835d62a','leo1311','Created','[{"modelId":"6f54644cc21a1bb22f9930e3","deploymentId":"e316db2c5bf73c0ec6e602d6","endpointUri":["https://api-aicloud.ad.infosys.com/v1/speech/transcribe/models/whisper-m/versions/1/infer"],"version":1}]','AICLOUD','s_reka@infosys.com','2023-05-23 06:21:54','','','null','2023-09-01 10:52:30','2023-05-23 06:21:54','2023-05-23 06:21:54','AICLOUD','0',NULL,'{"modifiedOn":"2023-05-23T06:14:16.458000","updatedBy":null,"isDeleted":false,"createdBy":"s_reka@infosys.com","name":"whisper","id":"6f684c9584f74717dbb34d84","contextUri":"/speech","createdOn":"2023-05-23T06:14:16.458000","projectId":"5a663746b15c40f3bf923f6ca835d62a","deployedModels":[{"modelId":"6f54644cc21a1bb22f9930e3","deploymentId":"e316db2c5bf73c0ec6e602d6","endpointUri":["https://api-aicloud.ad.infosys.com/v1/speech/transcribe/models/whisper-m/versions/1/infer"],"version":1}],"status":"Created"}','/speech','https://victlpth5-04:7875/','','Mapped','endpoint description');
            insert into mlfederatedendpoints (fed_id, adapter_id, app_name, fed_name, fed_org, app_org, status, deployed_models, adapter_alias, created_by, created_on, is_deleted, app_modified_by, fed_modified_by, app_modified_date, fed_modified_date, sync_date, endpoint_type, endpoint_likes, endpoint_metadata, raw_payload, context_uri, app_application, app_sample, app_status, app_description) values('6f684c9584f74717dbb34d88','AIPACLDT26697','starcodebase','starcodebase','5a663746b15c40f3bf923f6ca835d62a','leo1311','Created','[{"modelId":"6f54644cc21a1bb22f9930e5","deploymentId":"e316db2c5bf73c0ec6e602d0","endpointUri":["https://api-aicloud.ad.infosys.com/v1/code/complete/models/starcoderbase/versions/1/infer"],"version":1}]','AICLOUD','leapAccount01@infosys.com','2023-08-29 06:21:54','',NULL,'null',NULL,'2023-08-29 06:21:54','2023-08-29 06:21:54','AICLOUD','0',NULL,'{"modifiedOn":"2023-08-29T06:14:16.458000","updatedBy":null,"isDeleted":false,"createdBy":"leapAccount01@infosys.com","name":"starcodebase","id":"6f684c9584f74717dbb34d88","contextUri":"/code","createdOn":"2023-08-29T06:14:16.458000","projectId":"5a663746b15c40f3bf923f6ca835d62a","deployedModels":[{"modelId":"6f54644cc21a1bb22f9930e5","deploymentId":"e316db2c5bf73c0ec6e602d0","endpointUri":["https://api-aicloud.ad.infosys.com/v1/code/complete/models/starcoderbase/versions/1/infer"],"version":1}],"status":"Created"}','/code',NULL,NULL,'Mapped','endpoint description');        
            insert into mladapters (name, organization, connectionid, connectionname, spectemplatedomainname, description, category, createdby, createdon, lastmodifiedby, lastmodifiedon, apispec, isactive) values('AICloud-MLOps','leo1311','AIPACLD-12519','AICloud-MLOps-Connection','MlOps','AICloud MLOps','DYNAMIC','mohan.peta@ad.infosys.com','2023-09-01 16:24:25',NULL,NULL,'{"openapi":"3.0.2","info":{"version":1,"title":"AICloud-MLOps","description":""},"servers":[{"url":"https://ai-platform"}],"paths":{"/api/service/v1/models/list":{"get":{"dataset":"AIPPRJCT45166","parameters":[{"name":"adapter_instance","value":"AICloud-MLOps","in":"query","required":false,"description":"cloud provider name","schema":{"type":"string"}},{"name":"project","value":"leo1311","in":"query","required":false,"description":"project name","schema":{"type":"string"}},{"name":"isCached","value":"false","in":"query","required":false,"schema":{"type":"string"}}],"responses":{"200":{"description":"response","content":{"application/json":{"schema":{"type":"string"}}}},"default":{"description":"error","content":{"application/json":{"schema":{"type":"string"}}}}}}}},"components":{"schemas":{"input":{"properties":{}}},"securitySchemes":{"bearerAuth":{"type":"http","scheme":"bearer","bearerFormat":"JWT"},"basicAuth":{"type":"http","scheme":"basic"}},"security":[{"bearerAuth":[],"basicAuth":[]}]}}','Y');
            insert into mladapters (name, organization, connectionid, connectionname, spectemplatedomainname, description, category, createdby, createdon, lastmodifiedby, lastmodifiedon, apispec, isactive) values('AICloud-Bloom','leo1311','AIPA-CLD72732','AI-Cloud','CodeBuddy','AICloud Bloom\n','DYNAMIC','mohan.peta@ad.infosys.com','2023-09-27 08:11:03','mohan.peta@ad.infosys.com','2023-09-27 08:12:21','{"openapi":"3.0.2","info":{"version":1,"title":"AICloud-Bloom","description":""},"servers":[{"url":"https://victlpth5-04:8777"}],"paths":{"/api/service/codebuddy/v1/generate":{"post":{"dataset":"AIPGNRTK59223","parameters":[{"name":"adapter_instance","value":"AICloud-Bloom","in":"query","required":false,"description":"cloud provider name","schema":{"type":"string"}},{"name":"aip_project","value":"leo1311","in":"query","required":false,"schema":{"type":"string"}}],"requestBody":{"description":"request","required":true,"content":{"application/json":{"schema":{"$ref":"#/components/schemas/input","properties":{"example":"{\"inputs\":\"Cricket is best\"}"}}}},"value":"{\"inputs\":\"Cricket is best\"}"},"responses":{"200":{"description":"response","content":{"application/json":{"schema":{"type":"string"}}}},"default":{"description":"error","content":{"application/json":{"schema":{"type":"string"}}}}}}}},"components":{"schemas":{"input":{"properties":{}}},"securitySchemes":{"bearerAuth":{"type":"http","scheme":"bearer","bearerFormat":"JWT"},"basicAuth":{"type":"http","scheme":"basic"}},"security":[{"bearerAuth":[],"basicAuth":[]}]}}','Y');
            insert into mladapters (name, organization, connectionid, connectionname, spectemplatedomainname, description, category, createdby, createdon, lastmodifiedby, lastmodifiedon, apispec, isactive, executiontype) values('SNOW','leo1311','LEOSNW_M79040','snow_emf_usecase','Emf_usecase','','DYNAMIC','ameerbaji.shaik@infosys.com','2024-03-11 10:25:48','ameerbaji.shaik@infosys.com','2024-03-24 08:57:52','{"openapi":"3.0.2","info":{"version":1,"title":"SNOW","description":""},"servers":[{"url":"https://leap7:4006"}],"paths":{"/api/adapters/SNOW/GetIncidentBySysId/leo1311":{"get":{"dataset":"LEOGTNCD15888","parameters":[{"name":"accept","value":"application/json","description":"accept","required":"true","type":"string","in":"header"},{"name":"sys_id","value":"cf4e91e68774c210a79462ce8bbb351b","description":"sys_id","required":"true","type":"string","in":"query"}],"responses":{"200":{"description":"response","content":{"application/json":{"schema":{"type":"string"}}}},"default":{"description":"error","content":{"application/json":{"schema":{"type":"string"}}}}}}},"/api/adapters/SNOW/CreateIncident/leo1311":{"post":{"dataset":"LEOCRTNC77151","parameters":[{"name":"accept","value":"application/json","description":"accept","required":"true","type":"string","in":"header"},{"name":"sysparm_display_value","value":"true","description":"sysparm_display_value","required":"true","type":"string","in":"query"}],"requestBody":{"description":"request","required":true,"content":{"application/json":{"schema":{"$ref":"#/components/schemas/input","properties":{"example":"{}"}}}},"value":"{}"},"responses":{"200":{"description":"response","content":{"application/json":{"schema":{"type":"string"}}}},"default":{"description":"error","content":{"application/json":{"schema":{"type":"string"}}}}}}},"/api/adapters/SNOW/GetOpenIncidents/leo1311":{"get":{"dataset":"LEOGTPNC16633","parameters":[{"name":"accept","value":"application/json","description":"accept","required":"true","type":"string","in":"header"},{"name":"cmdb_ci","value":"","description":"cmdb_ci","required":"true","type":"string","in":"query"},{"name":"description","value":"","description":"description","required":"true","type":"string","in":"query"},{"name":"sysparm_query","value":"state!=7","description":"sysparm_query","required":"true","type":"string","in":"query"}],"responses":{"200":{"description":"response","content":{"application/json":{"schema":{"type":"string"}}}},"default":{"description":"error","content":{"application/json":{"schema":{"type":"string"}}}}}}},"/api/adapters/SNOW/UpdateIncident/leo1311":{"put":{"dataset":"LEOUPDTN59405","parameters":[{"name":"accept","value":"application/json","description":"accept","required":"true","type":"string","in":"header"},{"name":"sys_id","value":"","description":"param","required":"true","type":"string","in":"query"}],"requestBody":{"description":"request","required":true,"content":{"application/json":{"schema":{"$ref":"#/components/schemas/input","properties":{"example":"{\"work_notes\":\"Duplicate alert\"}"}}}},"value":"{\"work_notes\":\"Duplicate alert\"}"},"responses":{"200":{"description":"response","content":{"application/json":{"schema":{"type":"string"}}}},"default":{"description":"error","content":{"application/json":{"schema":{"type":"string"}}}}}},"post":{"dataset":"LEOUPDTN33130","parameters":[{"name":"accept","value":"application/json","description":"accept","required":"true","type":"string","in":"header"},{"name":"sys_id","value":"","description":"param","required":"true","type":"string","in":"query"}],"requestBody":{"description":"request","required":true,"content":{"application/json":{"schema":{"$ref":"#/components/schemas/input","properties":{"example":"{\"work_notes\":\"test worknotes\"}"}}}},"value":"{\"work_notes\":\"test worknotes\"}"},"responses":{"200":{"description":"response","content":{"application/json":{"schema":{"type":"string"}}}},"default":{"description":"error","content":{"application/json":{"schema":{"type":"string"}}}}}}},"/api/adapters/SNOW/GetI/leo1311":{"get":{"dataset":"LEOGTMRT44053","parameters":[{"name":"accept","value":"application/json","description":"accept","required":"true","type":"string","in":"header"},{"name":"sys_id","value":"dd1daf7e873c4610a79462ce8bbb3576","description":"param","required":"true","type":"string","in":"query"}],"responses":{"200":{"description":"response","content":{"application/json":{"schema":{"type":"string"}}}},"default":{"description":"error","content":{"application/json":{"schema":{"type":"string"}}}}}}},"/api/adapters/SNOW/GetI/leo1311/{sys_id}":{"get":{"dataset":"LEOGTCHF57613","parameters":[{"name":"accept","value":"application/json","description":"accept","required":"true","type":"string","in":"header"},{"name":"sys_id","value":"cf4e91e68774c210a79462ce8bbb351b","description":"param","required":"true","type":"string","in":"path"}],"responses":{"200":{"description":"response","content":{"application/json":{"schema":{"type":"string"}}}},"default":{"description":"error","content":{"application/json":{"schema":{"type":"string"}}}}}}}},"components":{"schemas":{"input":{"properties":{}}},"securitySchemes":{"bearerAuth":{"type":"http","scheme":"bearer","bearerFormat":"JWT"},"basicAuth":{"type":"http","scheme":"basic"}},"security":[{"bearerAuth":[],"basicAuth":[]}]}}','Y','REST');            
            insert into mlintstance (name, adaptername, organization, connectionid, connectionname, spectemplatedomainname, description, category, createdby, createdon, lastmodifiedby, lastmodifiedon) values('Bloom-Instance','AICloud-Bloom','leo1311','AIPA-CLD72732','AI-Cloud','CodeBuddy','Bloom Instance','DYNAMIC','mohan.peta@ad.infosys.com','2023-09-27 08:13:24',NULL,NULL);
            insert into mlintstance (name, adaptername, organization, connectionid, connectionname, spectemplatedomainname, description, category, createdby, createdon, lastmodifiedby, lastmodifiedon) values('AICloud-MLOps-Instance','AICloud-MLOps','leo1311','AIPACLD-12519','AICloud-MLOps-Connection','MlOps','AICloud MLOps Instance','DYNAMIC','mohan.peta@ad.infosys.com','2023-09-27 10:42:21',NULL,NULL);
            insert into mlintstance (name, adaptername, organization, connectionid, connectionname, spectemplatedomainname, description, category, createdby, createdon, lastmodifiedby, lastmodifiedon,executiontype) values('SNOW','SNOW','leo1311','LEOSNW_M79040','snow_emf_usecase','Emf_usecase','','DYNAMIC','ameerbaji.shaik@infosys.com','2024-03-11 12:17:32',NULL,NULL,'REST');     
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('lalith.basna@ad.infosys.com','2023-09-04 04:23:53','','Modern data architecture with llm chatbot is here to assist you the queries related to COVID-19 and weather',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPA-TWN38804_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','lalith.basna@ad.infosys.com','AI-Twin-Cloud_Data_Support','2023-09-04 04:23:54','AIPA-TWN38804','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('barad.vishal@ad.infosys.com','2023-09-07 09:59:19','','Langchain chatbot for IT support which contains chain of thought with modified chat UI',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPATWN_44866_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','barad.vishal@ad.infosys.com','AITwin_ITSupport_v1','2023-09-07 09:59:20','AIPATWN_44866','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('lalith.basna@ad.infosys.com','2023-09-06 12:18:08','','Langchain chatbor for HR support which contains chain of thought with modified chat UI',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPATWN_71043_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','lalith.basna@ad.infosys.com','AITwin_HRSupport_v1','2023-09-06 12:18:09','AIPATWN_71043','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('nusum.l@ad.infosys.com','2023-09-01 10:46:43','','Neo4j Product Chatbot - Chain of Thought',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPATWN-61193_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','nusum.l@ad.infosys.com','AI Twin - IT Support','2023-09-01 10:46:44','AIPATWN-61193','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('nusum.l@ad.infosys.com','2023-09-01 10:47:34','','Langchain Chatbot for HR Support',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPATWN-76061_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','nusum.l@ad.infosys.com','AI Twin- HR Support','2023-09-01 10:47:35','AIPATWN-76061','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('nusum.l@ad.infosys.com','2023-09-01 10:51:41','','Generate content using Bloom7l model',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPBLM7B26693_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','nusum.l@ad.infosys.com','bloom7b1','2023-09-01 10:51:42','AIPBLM7B26693','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('admin','2023-09-27 07:17:24','','Code Generative AI Using code-bison Model of Vertex AI Codey APIs. It allows users to seamlessly create test cases, generate code, translate between programming languages, and summarize code snippets by inputting a prompt.',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPCD_GN61740_leo1311.py\"],\"arguments\":[{\"key\":\"App\",\"value\":\"Code_GenAI\"}],\"dataset\":[]}}]}','admin','Code_GenAI','2023-09-27 07:17:25','AIPCD_GN61740','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('admin','2023-09-27 04:19:39','','Application is for Code Generation, Summarization and Conversion using AWS Bedrock services. User is Expected to Give prompt precisely.',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPCDBDY66967_leo1311.py\"],\"arguments\":[{\"key\":\"App\",\"value\":\"CodeBuddy_AWS-Bedrock\"}],\"dataset\":[]}}]}','admin','CodeBuddy_AWS-Bedrock','2023-09-27 04:19:40','AIPCDBDY66967','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('nusum.l@ad.infosys.com','2023-09-01 10:49:01','','App to generate the code,refining the code, translating the code, summarizing the code',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPCDGNY63846_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','nusum.l@ad.infosys.com','Codegen','2023-09-01 10:49:02','AIPCDGNY63846','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('nusum.l@ad.infosys.com','2023-09-01 10:40:09','','Tools',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPCGNZM95441_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','nusum.l@ad.infosys.com','Cognize Master','2023-09-01 10:40:10','AIPCGNZM95441','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('lalith.basna@ad.infosys.com','2023-09-06 08:21:52','','Completions is your creative companion, designed to spark your imagination which accepts prompt and model parameters as input, performs NLP related tasks using gpt-35-turbo model, returns humanlike response',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPCMPLT74112_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','lalith.basna@ad.infosys.com','Completions','2023-09-06 08:21:54','AIPCMPLT74112','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('nusum.l@ad.infosys.com','2023-09-01 10:49:46','','Text Generation',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPFLNT571838_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','nusum.l@ad.infosys.com','flant5-xl','2023-09-01 10:49:47','AIPFLNT571838','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('nusum.l@ad.infosys.com','2023-09-05 12:15:05','','',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPKNWLD83482_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','nusum.l@ad.infosys.com','Knowledge Portal','2023-09-05 12:15:06','AIPKNWLD83482','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('nusum.l@ad.infosys.com','2023-09-01 10:41:46','','Accepts text input, performs an embedding using Ada, use haystack framework to search',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPKNWLD91752_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','nusum.l@ad.infosys.com','Knowledge Search','2023-09-01 10:41:47','AIPKNWLD91752','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('nusum.l@ad.infosys.com','2023-09-01 10:40:52','','',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPRSPNS24226_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','nusum.l@ad.infosys.com','Responsible AI','2023-09-01 10:40:53','AIPRSPNS24226','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('nusum.l@ad.infosys.com','2023-09-01 10:53:47','','- Responsible by Design',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPSMRZW53439_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','nusum.l@ad.infosys.com','Summarize with Anonymization','2023-09-01 10:53:48','AIPSMRZW53439','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('nusum.l@ad.infosys.com','2023-09-01 10:52:31','','Using Stable diffusion model generate logos by providing brief description.',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPSTBLD68541_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','nusum.l@ad.infosys.com','stablediffusion','2023-09-01 10:52:32','AIPSTBLD68541','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('lalith.basna@ad.infosys.com','2023-09-12 11:13:49','','Tabular synthetic data generation',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPSYNTH92961_leo1311.py\"],\"arguments\":[{\"key\":\"App\",\"value\":\"synthetic-data-generation\"}],\"dataset\":[]}}]}','lalith.basna@ad.infosys.com','synthetic-data-generation','2023-09-12 11:13:50','AIPSYNTH92961','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('admin','2023-09-27 07:41:28','','Text Generative AI Using code-bison Model of Vertex AI. It allows users to seamlessly Generate Text  by inputting a prompt.',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPTXT_G16223_leo1311.py\"],\"arguments\":[{\"key\":\"App\",\"value\":\"Text_GenAI\"}],\"dataset\":[]}}]}','admin','Text_GenAI','2023-09-27 07:41:30','AIPTXT_G16223','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('nusum.l@ad.infosys.com','2023-09-01 10:55:01','','Searchable Library for video artifacts',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPVDLBR39889_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','nusum.l@ad.infosys.com','Video Library','2023-09-01 10:55:02','AIPVDLBR39889','leo1311','App','0',NULL,'App',NULL,'');
            insert into mlpipeline (created_by, created_date, deleted, description, job_id, json_content, lastmodifiedby, alias, lastmodifieddate, name, organization, type, version, tags, interfacetype, pipeline_metadata, is_template) values('nusum.l@ad.infosys.com','2023-09-01 10:50:49','','Convert audio to text',NULL,'{\"elements\":[{\"attributes\":{\"filetype\":\"Python3\",\"files\":[\"AIPWHSPR68023_leo1311.py\"],\"arguments\":[{\"name\":\"scriptPath\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"1\"},{\"name\":\"pipelineName\",\"value\":\"\",\"type\":\"Text\",\"alias\":\"\",\"index\":\"2\"}],\"dataset\":[]}}]}','nusum.l@ad.infosys.com','whisper-m','2023-09-01 10:50:50','AIPWHSPR68023','leo1311','App','0',NULL,'App',NULL,'');    
            insert into mleventjobmapping (body, description, eventname, organization, jobdetails, interfacetype) values('{}',NULL,'generateScript_LangChain','leo1311','[{"name":"LEOCDGNR10099","type":"pipeline","runtime":{"dsAlias":"","dsName":"","type":"Local"}}]',NULL);   
            insert into mlplugin (name, type, config, org, editortype) values('Langchain','Langchain','{"commands":["python -m streamlit run @!pipelinename!@_generatedCode.py --server.address 0.0.0.0","",""],"environment":{}}','Core','jsplumb');           
            insert into mlplugindetails (type, pluginname, plugindetails, org) values('Langchain','Langchain-1','{"formats":{"FunctionName":"text","requirements":"textarea","params":"list","script":"textarea"},"classname":"PythonScriptConfig","name":"Python Script","alias":"Python Script","parentCategory":"14","codeGeneration":{"imports":[],"script":"\n\n\n\n"},"id":1,"category":"BaseConfig","inputEndpoints":["dataset1","dataset2","dataset3"],"outputEndpoints":["out"],"attributes":{"FunctionName":"PythonScript","requirements":"","params":[],"script":"\rdef PythonScript( dataset):\n    #python-script Data\r\r    return dataset"}}','Core');
            insert into mlplugindetails (type, pluginname, plugindetails, org) values('Langchain','Langchain-2','{"formats":{"openai_api_key":"text","model_name":"text","openai_api_type":"text","deployment_name":"text","openai_api_base":"text","openai_api_version":"text"},"classname":"Azure OpenAI GPT 35 ","name":"Azure OpenAI GPT 35","alias":"Azure OpenAI GPT 35","parentCategory":"20","id":2,"codeGeneration":{"requirements":[],"imports":["from langchain.chat_models import AzureChatOpenAI"],"script":"def AzureOpenAIGPT35(deployment_name_param='', \r\n                    model_name_param='', \r\n                    openai_api_key_param='', \r\n                    openai_api_version_param='', \r\n                    openai_api_base_param='', \r\n                    openai_api_type_param=''\r\n                    ):\r\n    #initialize LLM object\r\n    llm = AzureChatOpenAI(    \r\n        deployment_name=deployment_name_param, \r\n        model_name=model_name_param, \r\n        openai_api_key=openai_api_key_param,\r\n        openai_api_version = openai_api_version_param, \r\n        openai_api_base=openai_api_base_param,\r\n        openai_api_type=openai_api_type_param,\r\n        streaming=True,\r\n        verbose=True\r\n        )\r\n    return llm\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n"},"category":"LLM","inputEndpoints":[],"outputEndpoints":["out1"],"attributes":{"openai_api_key":"85b968a4b5c84d849c99661788c2c1ed","model_name":"gpt-35-turbo","openai_api_type":"azure","deployment_name":"gtp35turbo","openai_api_base":"https://azureft.openai.azure.com/","openai_api_version":"2023-03-15-preview"}}','Core');
            insert into mlplugindetails (type, pluginname, plugindetails, org) values('Langchain','Langchain-3','{"formats":{"verbose":"bool"},"classname":"math_chain_tool_function","name":"math_chain_tool_function","alias":"Math Chain Tool Function","parentCategory":"16","id":3,"codeGeneration":{"requirements":[],"imports":["from langchain import LLMMathChain"],"script":"def math_chain_tool_function(llm, verbose_param=True):\r\n    # create tool function\r\n    tool_function = LLMMathChain.from_llm(llm=llm, verbose=verbose_param)\r\n    return tool_function\r\n\r\n\r\n\r\n\n"},"category":"Function Tools","inputEndpoints":["in1"],"outputEndpoints":["out1"],"attributes":{"verbose":"True"}}','Core');
            INSERT INTO mlplugindetails (type, pluginname, plugindetails, org) VALUES('Langchain', 'Langchain-4', N'{"formats":{"file_path":"text","file_system":"text","credential":"text","account_url":"text","decode":"text"},"classname":"datalake","name":"datalake","alias":"DataLake","parentCategory":"18","id":4,"codeGeneration":{"requirements":[],"imports":["from azure.storage.filedatalake import DataLakeServiceClient","from io import StringIO","import pandas as pd"],"script":"def datalake(account_url_param=' + NCHAR(39) + ', credential_param=' + NCHAR(39) + ', file_system_param=' + NCHAR(39) + ', file_path_param=' + NCHAR(39) + ', decode_param=' + NCHAR(39) + '):\r\n    # create employee data tool \r\n    client = DataLakeServiceClient( # authenticate to azure datalake\r\n                                  account_url=account_url_param,\r\n                                  credential=credential_param)\r\n                            \r\n    # azure data lake boilerplate to load from file system.  \r\n    file = client.get_file_system_client(file_system_param).get_file_client(file_path_param).download_file().readall().decode(decode_param) \r\n    \r\n    csv_file = StringIO(file) \r\n    #csv_file = ' + NCHAR(39) + '/folder/employee_data.csv' + NCHAR(39) + '\r\n    df = pd.read_csv(csv_file) # load employee_data.csv as dataframe\r\n    return df\r\n\r\n\r\n\r\n\r\n\r\n"},"category":"Data","inputEndpoints":[],"outputEndpoints":["out1"],"attributes":{"file_path":"employee_data/employee_data.csv","file_system":"file1","credential":"Y/tGx+bNiee2MD/hJ+4kzZTRE0uTDTQqAUy5eeeKKI09jjfI3QTv50qiSz1dIc/VHxpCJxJ8o4kDolHSwWWGMA==","account_url":"https://act1.dfs.core.windows.net/","decode":"utf-8"}}', 'Core');
INSERT INTO mlplugindetails (type, pluginname, plugindetails, org) VALUES('Langchain', 'Langchain-5', N'{"formats":{},"classname":"python_ast_repl_tool_function","name":"python_ast_repl_tool_function","alias":"Python Ast REPL Tool Function","parentCategory":"16","id":5,"codeGeneration":{"requirements":[],"imports":["from langchain.tools.python.tool import PythonAstREPLTool"],"script":"def python_ast_repl_tool_function(df):\r\n    # create tool function\r\n    tool_function = PythonAstREPLTool(locals={' + NCHAR(39) + 'df' + NCHAR(39) + ': df}) # set access of python_repl tool to the dataframe\r\n    return tool_function\r\n\r\n\r\n\r\n"},"category":"Function Tools","inputEndpoints":["in1"],"outputEndpoints":["out1"],"attributes":{}}', 'Core');
INSERT INTO mlplugindetails (type, pluginname, plugindetails, org) VALUES (
    'Langchain',
    'Langchain-6',
    '{
    "formats":{"openai_api_key":"text","openai_api_type":"text","model":"text","openai_api_base":"text","deployment":"text"},
    "classname":"Azure OpenAI text embedding ada 002",
    "name":"Azure OpenAI text embedding ada 002",
    "alias":"Azure OpenAI text embedding ada 002",
    "parentCategory":"18",
    "id":6,
    "codeGeneration":{
        "requirements":[],
        "imports":["from langchain.embeddings.openai import OpenAIEmbeddings"],
        "script":"def AzureOpenAItextembeddingada002(deployment_param='''', model_param='''', openai_api_key_param='''', openai_api_base_param='''', openai_api_type_param=''''):\n # initialize embeddings object; for use with user query/input\n embed = OpenAIEmbeddings(\n deployment=deployment_param,\n model=model_param,\n openai_api_key=openai_api_key_param,\n openai_api_base=openai_api_base_param,\n openai_api_type=openai_api_type_param,\n )\n\n return embed\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
    },
    "category":"Embedding",
    "inputEndpoints":[],
    "outputEndpoints":["out1"],
    "attributes":{
        "openai_api_key":"85b968a4b5c84d849c99661788c2c1ed",
        "openai_api_type":"azure",
        "model":"text-embedding-ada-002",
        "openai_api_base":"https://azureft.openai.azure.com/",
        "deployment":"openaiada2"
    }
}',
    'Core'
);
INSERT INTO mlplugindetails (type, pluginname, plugindetails, org) VALUES (
    'Langchain',
    'Langchain-7',
    '{
    "formats": {
        "environment": "text",
        "api_key": "text",
        "index_name": "text"
    },
    "classname": "setup_pinecode_vector",
    "name": "setup_pinecode_vector",
    "alias": "Setup Pinecode Vector",
    "parentCategory": "18",
    "id": 7,
    "codeGeneration": {
        "requirements": [],
        "imports": ["import pinecone"],
        "script": "def setup_pinecode_vector(api_key_param='''', environment_param='''', index_name_param=''''):\n    # initialize pinecone client and connect to pinecone index\n    pinecone.init(\n            api_key=api_key_param,  \n            environment=environment_param \n    )\n\n    index_name = index_name_param\n    index = pinecone.Index(index_name) # connect to pinecone index\n    return index\n\n\n\n"
    },
    "category": "vector",
    "inputEndpoints": [],
    "outputEndpoints": ["out1"],
    "attributes": {
        "environment": "us-west1-gcp-free",
        "api_key": "b02bfd20-0885-4f0e-99ae-2873749d686d",
        "index_name": "tk-policy"
    }
}',
    'Core'
);
INSERT INTO mlplugindetails (type, pluginname, plugindetails, org) VALUES (
    'Langchain',
    'Langchain-8',
    '{
    "formats": {
        "text_field": "text"
    },
    "classname": "vector_store",
    "name": "vector_store",
    "alias": "Vector Store",
    "parentCategory": "18",
    "id": 8,
    "codeGeneration": {
        "requirements": [],
        "imports": ["from langchain.vectorstores import Pinecone"],
        "script": "def vector_store(embed, index, text_field_param=''''):\n    vectorstore = Pinecone(\n        index, embed.embed_query, text_field_param\n    )\n    return vectorstore\n\n\n\n"
    },
    "category": "Data",
    "inputEndpoints": ["in1","in2"],
    "outputEndpoints": ["out1"],
    "attributes": {
        "text_field": "text"
    }
}',
    'Core'
);
INSERT INTO mlplugindetails (type, pluginname, plugindetails, org) VALUES (
    'Langchain',
    'Langchain-9',
    '{
    "formats": {
        "chain_type": "text"
    },
    "classname": "retrieval_qa_tool_function",
    "name": "retrieval_qa_tool_function",
    "alias": "Retrieval QA Tool Function",
    "parentCategory": "17",
    "id": 9,
    "codeGeneration": {
        "requirements": [],
        "imports": ["from langchain.chains import RetrievalQA"],
        "script": "def retrieval_qa_tool_function(llm, retriever_obj, chain_type_param=''''):\n    # create tool function\n    # initialize vectorstore retriever object\n    timekeeping_policy = RetrievalQA.from_chain_type(\n        llm=llm,\n        chain_type=chain_type_param,\n        retriever=retriever_obj,\n    )\n    return timekeeping_policy\n\n"
    },
    "category": "Tool Function",
    "inputEndpoints": ["in1","in2"],
    "outputEndpoints": ["out1"],
    "attributes": {
        "chain_type": "stuff"
    }
}',
    'Core'
);
INSERT INTO mlplugindetails (type, pluginname, plugindetails, org) VALUES (
    'Langchain',
    'Langchain-11',
    '{
    "formats": {
        "prefix_argument": "textarea",
        "verbose": "bool",
        "agent": "text",
        "max_execution_time": "text",
        "early_stopping_method": "text"
    },
    "classname": "Initialize Agent",
    "name": "Initialize Agent",
    "alias": "Initialize Agent",
    "parentCategory": "16",
    "id": 11,
    "codeGeneration": {
        "requirements": [],
        "imports": [
            "from langchain.agents import AgentType",
            "from langchain.agents import initialize_agent"
        ],
        "script": "def InitializeAgent(tools, llm, agent_param='''', max_execution_time_param='''', early_stopping_method_param='''', prefix_argument_param='''', verbose_param=''''):\n    # change the value of the prefix argument in the initialize_agent function. This will overwrite the default prompt template of the zero shot agent type\n    agent_kwargs = {''prefix'': prefix_argument_param}\n    \n    \n    # initialize the LLM agent\n    agent = initialize_agent(tools, \n                             llm, \n                             agent=agent_param, \n                             verbose=verbose_param, \n                             max_execution_time=int(max_execution_time_param), \n                             early_stopping_method=early_stopping_method_param,\n                             agent_kwargs=agent_kwargs\n                             )\n    # agent = initialize_agent(tools, \n    #                          llm, \n    #                          agent=''zero-shot-react-description'', \n    #                          verbose=True, \n    #                          agent_kwargs=agent_kwargs\n    #                          )\n    return agent\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
    },
    "category": "Agent",
    "inputEndpoints": ["in1","in2"],
    "outputEndpoints": ["out1"],
    "attributes": {
        "prefix_argument": "",
        "verbose": "True",
        "agent": "zero-shot-react-description",
        "max_execution_time": "20",
        "early_stopping_method": "generate"
    }
}',
    'Core'
);
INSERT INTO mlplugindetails (type, pluginname, plugindetails, org) VALUES (
    'Langchain',
    'Langchain-12',
    '{
    "formats": {
        "azure_cognitive_search_index_name": "text",
        "azure_cognitive_search_service_name": "text",
        "azure_cognitive_search_api_key": "text"
    },
    "classname": "setup_azure_cognitive_environ",
    "name": "setup_azure_cognitive_environ",
    "alias": "setup_azure_cognitive_environ",
    "parentCategory": "19",
    "id": 12,
    "codeGeneration": {
        "requirements": [],
        "imports": ["import os"],
        "script": "def setup_azure_cognitive_environ(azure_cognitive_search_service_name_param='''', \n                                azure_cognitive_search_index_name_param='''', \n                                azure_cognitive_search_api_key_param=''''\n                                ):\n    os.environ[''AZURE_COGNITIVE_SEARCH_SERVICE_NAME''] = azure_cognitive_search_service_name_param\n    os.environ[''AZURE_COGNITIVE_SEARCH_INDEX_NAME''] =azure_cognitive_search_index_name_param\n    os.environ[''AZURE_COGNITIVE_SEARCH_API_KEY''] = azure_cognitive_search_api_key_param\n    return True\n\n"
    },
    "category": "retriever",
    "inputEndpoints": [],
    "outputEndpoints": ["out1"],
    "attributes": {
        "azure_cognitive_search_index_name": "azureblob-docs-index",
        "azure_cognitive_search_service_name": "search-ins",
        "azure_cognitive_search_api_key": "4FNKXW99u0BfMTXd2s1LNo10N6CxPafTwi7jLGa7cnAzSeB6HOL4"
    }
}',
    'Core'
);
INSERT INTO mlplugindetails (type, pluginname, plugindetails, org) VALUES (
    'Langchain',
    'Langchain-13',
    '{
    "formats": {},
    "classname": "azure_cognitive_search_retriever",
    "name": "azure_cognitive_search_retriever",
    "alias": "azure_cognitive_search_retriever",
    "parentCategory": "19",
    "id": 13,
    "codeGeneration": {
        "requirements": [],
        "imports": ["from langchain.retrievers import AzureCognitiveSearchRetriever"],
        "script": "def azure_cognitive_search_retriever(azure_cognitive_environ_flag=False):\n    retriever = None\n    if azure_cognitive_environ_flag:\n        retriever = AzureCognitiveSearchRetriever()\n    else:\n        print(''Please Setup/Configure AZURE_COGNITIVE_SEARCH environment'')\n    return retriever\n\n"
    },
    "category": "retriever",
    "inputEndpoints": ["in1"],
    "outputEndpoints": ["out1"],
    "attributes": {}
}',
    'Core'
);
INSERT INTO mlplugindetails (type, pluginname, plugindetails, org) VALUES (
    'Langchain',
    'Langchain-14',
    '{
    "id": 14,
    "name": "Common Node",
    "alias": "Common Node",
    "category": "Common Node",
    "inputEndpoints": [],
    "outputEndpoints": [],
    "codeGeneration": {
        "imports": [],
        "requirements": [],
        "script": ""
    },
    "parentCategory": "",
    "classname": "Common Node",
    "attributes": {},
    "formats": {}
}',
    'Core'
);
INSERT INTO mlplugindetails (type, pluginname, plugindetails, org) VALUES (
    'Langchain',
    'Langchain-15',
    '{
    "formats": {
        "name": "text",
        "description": "textarea"
    },
    "classname": "Initialize Tool",
    "name": "Initialize Tool",
    "alias": "Initialize Tool",
    "parentCategory": "16",
    "id": 15,
    "codeGeneration": {
        "requirements": [],
        "imports": ["from langchain.agents import Tool"],
        "script": "def InitializeTool(function_obj, name_param = '''', description_param=''''):\n    tool =  Tool(\n                    name = name_param,\n                    func=function_obj.run,\n                    description = description_param\n                )\n    return tool\n\n\n\n\n\n\n\n\n\n"
    },
    "category": "Tool",
    "inputEndpoints": ["in1"],
    "outputEndpoints": ["out1"],
    "attributes": {
        "name": "",
        "description": ""
    }
}',
    'Core'
);
INSERT INTO mlplugindetails (type, pluginname, plugindetails, org) VALUES (
    'Langchain',
    'Langchain-16',
    '{
    "id": 16,
    "name": "Tool",
    "alias": "Tool",
    "category": "Tool",
    "inputEndpoints": [],
    "outputEndpoints": [],
    "codeGeneration": {
        "imports": [],
        "requirements": [],
        "script": ""
    },
    "parentCategory": "",
    "classname": "Tool",
    "attributes": {},
    "formats": {}
}',
    'Core'
);
INSERT INTO mlplugindetails (type, pluginname, plugindetails, org) VALUES (
    'Langchain',
    'Langchain-17',
    '{
    "id": 17,
    "name": "Chain",
    "alias": "Chain",
    "category": "Chain",
    "inputEndpoints": [],
    "outputEndpoints": [],
    "codeGeneration": {
        "imports": [],
        "requirements": [],
        "script": ""
    },
    "parentCategory": "",
    "classname": "Chain",
    "attributes": {},
    "formats": {}
}',
    'Core'
);
INSERT INTO mlplugindetails (type, pluginname, plugindetails, org) VALUES (
    'Langchain',
    'Langchain-18',
    '{
    "id": 18,
    "name": "DataConnection",
    "alias": "DataConnection",
    "category": "DataConnection",
    "inputEndpoints": [],
    "outputEndpoints": [],
    "codeGeneration": {
        "imports": [],
        "requirements": [],
        "script": ""
    },
    "parentCategory": "",
    "classname": "DataConnection",
    "attributes": {},
    "formats": {}
}',
    'Core'
);
INSERT INTO mlplugindetails (type, pluginname, plugindetails, org) VALUES (
    'Langchain',
    'Langchain-19',
    '{
    "id": 19,
    "name": "Retriever",
    "alias": "Retriever",
    "category": "Retriever",
    "inputEndpoints": [],
    "outputEndpoints": [],
    "codeGeneration": {
        "imports": [],
        "requirements": [],
        "script": ""
    },
    "parentCategory": "",
    "classname": "Retriever",
    "attributes": {},
    "formats": {}
}',
    'Core'
);
INSERT INTO mlplugindetails (type, pluginname, plugindetails, org) VALUES (
    'Langchain',
    'Langchain-20',
    '{
    "id": 20,
    "name": "Memory",
    "alias": "Memory",
    "category": "Memory",
    "inputEndpoints": [],
    "outputEndpoints": [],
    "codeGeneration": {
        "imports": [],
        "requirements": [],
        "script": ""
    },
    "parentCategory": "",
    "classname": "Memory",
    "attributes": {},
    "formats": {}
}',
    'Core'
);
            insert into mlplugindetails (type, pluginname, plugindetails, org) values('Langchain','Langchain-21','{"id":21,"name":"prompt_templete","alias":"prompt_templete","category":"","inputEndpoints":[],"outputEndpoints":["out1"],"codeGeneration":{"imports":["from langchain.prompts import PromptTemplate"],"requirements":[],"script":"def prompt_templete(templete_param='', input_var_param=''):\r\n    SUPPORT_PROMPT = PromptTemplate(\r\n        template=templete_param, input_variables=input_var_param.split('','')\r\n    )\r\n\r\n    return SUPPORT_PROMPT\n"},"parentCategory":"prompt_templete","classname":"","attributes":{"templete":"","input_var":"context,question"},"formats":{"templete":"textarea","input_var":"text"}}','Core');
            insert into mlplugindetails (type, pluginname, plugindetails, org) values('Langchain','Langchain-22','{"formats":{"input_var":"text","templete":"textarea","validate_template":"bool","template_format":"text"},"classname":"Prompt Templates","name":"Prompt Templates","alias":"Prompt Templates","parentCategory":"23","id":22,"codeGeneration":{"requirements":[],"imports":["from langchain.prompts import PromptTemplate"],"script":"def PromptTemplates(templete_param='', input_var_param='', validate_template_param=True, template_format_param=''):\r\n    SUPPORT_PROMPT = PromptTemplate(\r\n        template=templete_param, \r\n        input_variables=input_var_param.split('',''),\r\n        validate_template=validate_template_param,\r\n        template_format=template_format_param,\r\n\r\n    )\r\n    return SUPPORT_PROMPT\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n"},"category":"Prompt","inputEndpoints":[],"outputEndpoints":["out1"],"attributes":{"input_var":"context,question","templete":"","validate_template":"True","template_format":"f-string"}}','Core');
            insert into mlplugindetails (type, pluginname, plugindetails, org) values('Langchain','Langchain-23','{"id":23,"name":"Prompt","alias":"Prompt","category":"","inputEndpoints":[],"outputEndpoints":[],"codeGeneration":{"imports":[],"requirements":[],"script":""},"parentCategory":"","classname":"Prompt","attributes":{},"formats":{}}','Core');

            insert into mlplugindetails (type, pluginname, plugindetails, org) values('Langchain','Langchain-24','{"formats":{"prompt_text":"textarea","markdown":"textarea","header":"text"},"classname":"Chat UI","name":"Chat UI","alias":"Chat UI","parentCategory":"14","id":24,"codeGeneration":{"requirements":[],"imports":["import streamlit as st","import random","from streamlit_chat import message","import os","from langchain.callbacks import StreamlitCallbackHandler"],"script":"from langchain.callbacks.base import BaseCallbackHandler\r\n\r\nclass StreamHandler(BaseCallbackHandler):\r\n    def __init__(self, initial_text=''Start..''):\r\n        self.text = initial_text\r\n\r\n    def on_text(self, text: str, **kwargs) -> None:\r\n        starter_text = ''Begin!''\r\n        self.text = text\r\n        if (self.text.find(starter_text) > 0):\r\n            self.text = self.text[self.text.find(starter_text) + len(starter_text):]\r\n        st.session_state[''thoughts''][len(st.session_state[''thoughts'']) - 1] = self.text\r\n        message(self.text, key=self.text + ''_chain_of_thoughts'')\r\n\r\ndef ChatUI(agent, header_param=''? LLM HR Chatbot - Chain of Thought Demo'', markdown_param='', prompt_text_param=''):    \r\n    print(''Initializing the streamlit app..'')\r\n    \r\n    st.header(header_param)\r\n    st.markdown(prompt_text_param, unsafe_allow_html=True)\r\n    st.markdown(markdown_param, unsafe_allow_html=True)   \r\n    \r\n    stream_handler1 = StreamHandler()\r\n\r\n    if ''past'' not in st.session_state:\r\n        st.session_state[''past''] = []\r\n    if ''generated'' not in st.session_state:\r\n        st.session_state[''generated''] = []\r\n    \r\n    if ''thoughts'' not in st.session_state:\r\n        st.session_state[''thoughts''] = []\r\n    \r\n    if ''input_message_key'' not in st.session_state:\r\n        st.session_state[''input_message_key''] = str(random.random())\r\n    \r\n    chat_container = st.container()\r\n    user_input = st.text_input(''Type your message and press Enter to send.'', key=st.session_state[''input_message_key''])\r\n    \r\n    if st.button(''Send''):\r\n        try:\r\n            message(user_input, is_user=True, key=user_input + ''_user'')\r\n            st.session_state[''thoughts''].append('')\r\n            response = agent.run(user_input, callbacks=[stream_handler1])\r\n        except Exception as e:\r\n            print(''The traceback is: '', e)\r\n            response = ''Invalid input. Please try again''\r\n        \r\n        \r\n        message(response, key=user_input)\r\n    \r\n        st.session_state[''past''].append(user_input)\r\n        st.session_state[''generated''].append(response)\r\n    \r\n        st.session_state[''input_message_key''] = str(random.random())\r\n    \r\n        st.experimental_rerun()\r\n    \r\n    if st.session_state[''generated'']:\r\n        with chat_container:\r\n            for i in range(len(st.session_state[''generated''])):\r\n                message(st.session_state[''past''][i], is_user=True, key=str(i) + ''_user'')\r\n                message(st.session_state[''thoughts''][i], key=str(i) + ''_chain_of_thoughts'')\r\n                message(st.session_state[''generated''][i], key=str(i))   \r\n\n"},"category":"Chat UI","inputEndpoints":["in1"],"outputEndpoints":[],"attributes":{"prompt_text":"","markdown":"","header":"? LLM HR Chatbot - Chain of Thought Demo"}}','Core');
            insert into mlplugindetails (type, pluginname, plugindetails, org) values('Langchain','Langchain-25','{"formats":{"chain_type":"text"},"classname":"Retrieval Chain","name":"Retrieval Chain","alias":"Retrieval Chain","parentCategory":"17","id":25,"codeGeneration":{"requirements":[],"imports":["from langchain.chains import RetrievalQA"],"script":"def RetrievalChain(llm, retriever_obj, prompt = None, chain_type_param='',):\r\n    # create tool function\r\n    # initialize vectorstore retriever object\r\n    chain_type_kwargs = None\r\n    if prompt is not None:\r\n        chain_type_kwargs={''prompt'': prompt}\r\n    timekeeping_policy = RetrievalQA.from_chain_type(\r\n        llm=llm,\r\n        chain_type=chain_type_param,\r\n        retriever=retriever_obj.as_retriever(),\r\n        chain_type_kwargs = chain_type_kwargs\r\n    )\r\n    return timekeeping_policy\r\n\r\n\r\n\r\n\r\n\r\n\n"},"category":"Chain","inputEndpoints":["in1","in2","in3"],"outputEndpoints":["out1"],"attributes":{"chain_type":"stuff"}}','Core');
            insert into mlplugindetails (type, pluginname, plugindetails, org) values('Langchain','Langchain-26','{"formats":{"vector_store_address":"text","vector_store_password":"text","index_name":"text"},"classname":"Azure Searches","name":"Azure Searches","alias":"Azure Searches","parentCategory":"18","id":26,"codeGeneration":{"requirements":[],"imports":["from langchain.vectorstores.azuresearch import AzureSearch"],"script":"def AzureSearches(embeddings, vector_store_address_param='', vector_store_password_param='', index_name_param=''):\r\n    vector_store_address: str = vector_store_address_param\r\n    vector_store_password: str = vector_store_password_param\r\n\r\n    index_name: str = index_name_param\r\n    store: AzureSearch = AzureSearch(\r\n        azure_search_endpoint=vector_store_address,\r\n        azure_search_key=vector_store_password,\r\n        index_name=index_name,\r\n        embedding_function=embeddings.embed_query,\r\n    )\r\n\r\n    return store\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n"},"category":"vector","inputEndpoints":["in1"],"outputEndpoints":["out1"],"attributes":{"vector_store_address":"https://search-ins.search.windows.net","vector_store_password":"4FNKXW99u0BfMTXd2s1LNo10N6CxPafTwi7jLGa7cnAzSeB6HOL4","index_name":"neo4j-sales-kb-index"}}','Core');
            insert into mlplugindetails (type, pluginname, plugindetails, org) values('Langchain','Langchain-28','{"formats":{},"classname":"parse_catalog","name":"parse_catalog","alias":"parse_catalog","parentCategory":"29","id":28,"codeGeneration":{"requirements":[],"imports":[],"script":"def parse_catalog(gdc, glue_client):\r\n    #Connect to Glue catalog\r\n    #get metadata of redshift serverless tables\r\n    columns_str=''\r\n    \r\n    for db in gdc:\r\n        response = glue_client.get_tables(DatabaseName = db)\r\n        for tables in response[''TableList'']:\r\n#             print(tables)\r\n            #classification in the response for s3 and other databases is different. Set classification based on the response location\r\n            if tables[''StorageDescriptor''][''Location''].startswith(''s3''):  classification=''s3'' \r\n            else:  classification = tables[''Parameters''][''classification'']\r\n            for columns in tables[''StorageDescriptor''][''Columns'']:\r\n                    dbname,tblname,colname=tables[''DatabaseName''],tables[''Name''],columns[''Name'']\r\n                    columns_str=columns_str+f''\\n{classification}|{dbname}|{tblname}|{colname}'' \r\n\r\n    #API\r\n    ## Append the metadata of the API to the unified glue data catalog\r\n    columns_str=columns_str+''\\n''+(''api|meteo|weather|weather'')\r\n    global glue_catalog\r\n    glue_catalog = columns_str\r\n    return columns_str\r\n\r\n\r\n\r\n\n"},"category":"parse_catalog","inputEndpoints":["in1","in2"],"outputEndpoints":["out1"],"attributes":{}}','Core');
            insert into mlplugindetails (type, pluginname, plugindetails, org) values('Langchain','Langchain-29','{"id":29,"name":"Parse","alias":"Parse","category":"Parse","inputEndpoints":[],"outputEndpoints":[],"codeGeneration":{"imports":[],"requirements":[],"script":""},"parentCategory":"","classname":"Parse","attributes":{},"formats":{}}','Core');
            insert into mlplugindetails (type, pluginname, plugindetails, org) values('Langchain','Langchain-30','{"formats":{"templete":"textarea","input_var":"text","validate_template":"bool","template_format":"text"},"classname":"Dynamic_PromptTemplates","name":"Dynamic_PromptTemplates","alias":"Dynamic_PromptTemplates","parentCategory":"23","id":30,"codeGeneration":{"requirements":[],"imports":[],"script":"def Dynamic_PromptTemplates(temp,templete_param='', input_var_param='', validate_template_param=True, template_format_param=''):    \r\n    SUPPORT_PROMPT = PromptTemplate(template=templete_param, input_variables=input_var_param.split('',''), validate_template=validate_template_param, template_format=template_format_param)\r\n    return SUPPORT_PROMPT\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n"},"category":"Dynamic_PromptTemplates","inputEndpoints":["in1"],"outputEndpoints":["out1"],"attributes":{"templete":"","input_var":"query","validate_template":"True","template_format":"f-string"}}','Core');
            insert into mlplugindetails (type, pluginname, plugindetails, org) values('Langchain','Langchain-31','{"id":31,"name":"Chat UI V1","alias":"Chat UI V1","category":"Chat UI V1","inputEndpoints":["in1"],"outputEndpoints":[],"codeGeneration":{"imports":["import streamlit as st","from langchain.callbacks import StreamlitCallbackHandler","import os"],"requirements":[],"script":"def ChatUIV1(agent, header_param=''? LLM HR Chatbot - Chain of Thought Demo'', markdown_param='', prompt_text_param=''):    \r\n    \r\n    def on_btn_click():\r\n        del st.session_state.messages[:]\r\n\r\n    st.set_page_config(initial_sidebar_state=''auto'')   \r\n    st.header(header_param)\r\n    st.markdown(prompt_text_param, unsafe_allow_html=True)\r\n    st.markdown(markdown_param, unsafe_allow_html=True) \r\n\r\n    st.sidebar.title('' Chain of thoughts'')\r\n    \r\n    stream_container = st.sidebar.container()\r\n    st_callback = StreamlitCallbackHandler(stream_container)\r\n        \r\n    if ''messages'' not in st.session_state:        \r\n        st.session_state.messages = []\r\n        \r\n    for message in st.session_state.messages:\r\n        with st.chat_message(message[''role'']):\r\n            st.markdown(message[''content''], unsafe_allow_html=True)\r\n\r\n    if prompt := st.chat_input(''Ask your question?''):\r\n        st.session_state.messages.append({''role'': ''user'', ''content'': prompt})\r\n        with st.chat_message(''user''):\r\n            st.markdown(prompt)\r\n        \r\n        with st.chat_message(''assistant''):\r\n            message_placeholder = st.empty()\r\n            full_response = ''\r\n            try:      \r\n                reply = agent.run(prompt, callbacks=[st_callback])                \r\n            except Exception as e:\r\n                reply = ''Invalid input. Please try again''\r\n                \r\n            for response in reply:\r\n                full_response += response\r\n                message_placeholder.markdown(full_response + ''|'', unsafe_allow_html=True)\r\n            message_placeholder.markdown(full_response, unsafe_allow_html=True)\r\n        st.session_state.messages.append({''role'': ''assistant'', ''content'': full_response})\r\n        st.button(''Clear chat'', on_click=on_btn_click)\r\n\n"},"parentCategory":"14","classname":"Chat UI V1","attributes":{"prompt_text":"","markdown":"","header":"? LLM HR Chatbot - Chain of Thought Demo"},"formats":{"prompt_text":"textarea","markdown":"textarea","header":"text"}}','Core');
            insert into mlplugindetails (type, pluginname, plugindetails, org) values('Langchain','Langchain-32','{"formats":{"prompt_text":"textarea","markdown":"textarea","header":"text"},"classname":"Chat UI V2","name":"Chat UI V2","alias":"Chat UI V2","parentCategory":"14","id":32,"codeGeneration":{"requirements":[],"imports":["from langchain.callbacks import StreamlitCallbackHandler","import streamlit as st","from langchain.callbacks.streaming_stdout_final_only import FinalStreamingStdOutCallbackHandler"],"script":"def ChatUIV2(agent, header_param=''? LLM HR Chatbot - Chain of Thought Demo'', markdown_param='', prompt_text_param=''):    \r\n   \r\n    def on_btn_click():\r\n        del st.session_state.messages[:]\r\n\r\n    st.set_page_config(initial_sidebar_state=''auto'')   \r\n    st.header(header_param)\r\n    st.markdown(prompt_text_param, unsafe_allow_html=True)\r\n    st.markdown(markdown_param, unsafe_allow_html=True) \r\n\r\n    st.sidebar.title(''Chain of thoughts'')\r\n    \r\n    stream_container = st.sidebar.container()\r\n    stream_handler1 = StreamlitCallbackHandler(stream_container)\r\n    stream_handler2 = FinalStreamingStdOutCallbackHandler()\r\n\r\n    if ''messages'' not in st.session_state:        \r\n        st.session_state.messages = []\r\n        \r\n    for message in st.session_state.messages:\r\n        with st.chat_message(message[''role'']):\r\n            st.markdown(message[''content''], unsafe_allow_html=True)\r\n    \r\n    if prompt := st.chat_input(''Ask your question?''):\r\n        st.session_state.messages.append({''role'': ''user'', ''content'': prompt})\r\n        with st.chat_message(''user''):\r\n            st.markdown(prompt)\r\n        \r\n        with st.chat_message(''assistant''):\r\n            message_placeholder = st.empty()\r\n            full_response = ''\r\n            try:      \r\n                reply = agent.run(prompt, callbacks=[stream_handler1,stream_handler2])                \r\n            except Exception as e:\r\n                print(e)\r\n                reply = ''Invalid input. Please try again''\r\n                \r\n            for response in reply:\r\n                full_response += response\r\n                message_placeholder.markdown(full_response + ''|'', unsafe_allow_html=True)\r\n            message_placeholder.markdown(full_response, unsafe_allow_html=True)\r\n        st.session_state.messages.append({''role'': ''assistant'', ''content'': full_response})\r\n        st.button(''Clear chat'', on_click=on_btn_click)\r\n\r\n\r\n\n"},"category":"Chat UI V2","inputEndpoints":["in1"],"outputEndpoints":[],"attributes":{"prompt_text":"","markdown":"","header":"? LLM HR Chatbot - Chain of Thought Demo"}}','Core');
            INSERT INTO usm_role_permissions (permission,role) VALUES ((SELECT id FROM usm_permissions WHERE permission='pipeline-delete'), 1);
            INSERT INTO usm_role_permissions (permission,role) VALUES ((SELECT id FROM usm_permissions WHERE permission='pipeline-create'), 1); 
            insert into mldataset (attributes, dataset_type, description, exp_status, name, organization, schemajson, type, backing_dataset, dataset_schema, datasource, lastmodifiedby, lastmodifieddate, alias, context, is_approval_required, is_permission_managed, is_inbox_required, is_audit_required, is_archival_enabled, archival_config, dashboard, metadata, modeltype, views, taskdetails, tags, interfacetype, adaptername, isadapteractive) values('{"bodyType":"Text","PathVariables":[],"Cacheable":false,"transformData":true,"RequestMethod":"GET","Headers":[{"value":"leapAccount01@infosys.com","key":"userId"},{"value":"application/json","key":"accept"}],"TransformationScript":"\"import groovy.json.*\\n\\ndef inpResponse = \\\"$inputJson\\\"\\n\\ndef jsonMap = new groovy.json.JsonSlurper().parseText(inpResponse)\\ndef data = jsonMap.data.models\\nfor (model in data)\\n{\\nmodel.modelname = model.name\\nmodel.type= \\\"AICloud\\\"\\nmodel.lastModified= model.modifiedOn\\nmodel.description= model.description\\nmodel.version = model.version\\nmodel.modelpath= model.modelDir\\nmodel.STATUS= model.status\\n}\\nreturn groovy.json.JsonOutput.toJson(data)\"","bodyOption":"raw","QueryParams":[],"preTransformationScript":"\"import groovy.json.*\\n\\ndef inpBody = \\\"$Body\\\"\\ndef inpQueryParams = \\\"$QueryParams\\\"\\ndef inpHeaders = \\\"$Headers\\\"\\ndef inpbodyType = \\\"$bodyType\\\"\\ndef inpPathVariables = \\\"$PathVariables\\\"\\ndef inpUrl = \\\"$Url\\\"\\ndef inpConfigVariables = \\\"$ConfigVariables\\\"\\n\\n//start your code from here\\n\\nreturn JsonOutput.prettyPrint(JsonOutput.toJson([Body:{preprocessed_Body}, QueryParams:{preprocessed_QueryParams},Headers:{preprocessed_Headers},bodyType:{preprocessed_bodyType},PathVariables:{preprocessed_PathVariables},Url:{preprocessed_Url},ConfigVariables:{preprocessed_ConfigVariables}]))\\n\"","Url":"https://api-aicloud.ad.infosys.com/api/v1/models?projectId=5a663746b15c40f3bf923f6ca835d62a"}',NULL,NULL,'0','AIPPRJCT45166','leo1311',NULL,'rw',NULL,NULL,'AIPACLDT26697','admin','2023-07-26 13:50:27','projects_models_list',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'\"\"',NULL,'\"\"','adapter','AICloud-MLOps','Y');
            insert into mldataset (attributes, dataset_type, description, exp_status, name, organization, schemajson, type, backing_dataset, dataset_schema, datasource, lastmodifiedby, lastmodifieddate, alias, context, is_approval_required, is_permission_managed, is_inbox_required, is_audit_required, is_archival_enabled, archival_config, dashboard, metadata, modeltype, views, taskdetails, tags, interfacetype, adaptername, isadapteractive) values('{"bodyType":"JSON","PathVariables":[],"Cacheable":false,"transformData":false,"RequestMethod":"POST","Headers":[{"value":"application/json","key":"Content-Type"}],"TransformationScript":"\"import groovy.json.*\\n\\ndef inpResponse = \\\"$inputJson\\\"\\n//start your code from here\\n\"","bodyOption":"raw","QueryParams":[],"preTransformationScript":"\"import groovy.json.*\\n\\ndef inpBody = \\\"$Body\\\"\\ndef inpQueryParams = \\\"$QueryParams\\\"\\ndef inpHeaders = \\\"$Headers\\\"\\ndef inpbodyType = \\\"$bodyType\\\"\\ndef inpPathVariables = \\\"$PathVariables\\\"\\ndef inpUrl = \\\"$Url\\\"\\ndef inpConfigVariables = \\\"$ConfigVariables\\\"\\n\\n//start your code from here\\n\\nreturn JsonOutput.prettyPrint(JsonOutput.toJson([Body:{preprocessed_Body}, QueryParams:{preprocessed_QueryParams},Headers:{preprocessed_Headers},bodyType:{preprocessed_bodyType},PathVariables:{preprocessed_PathVariables},Url:{preprocessed_Url},ConfigVariables:{preprocessed_ConfigVariables}]))\\n\"","Body":"{\"inputs\":\"Cricket is best\"}","Url":"/v1/language/generate/models/bloom7b1/versions/1/infer"}',NULL,'','0','AIPGNRTK59223','leo1311',NULL,'rw',NULL,NULL,'AIPACLDT26697','mohan.peta@ad.infosys.com','2023-09-27 08:12:20','generate',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'\"\"',NULL,'\"','adapter','AICloud-Bloom','Y');
            insert into mldatasource ( connectiondetails, description, dshashcode, name, organization, salt, type, category, activetime, lastmodifiedby, lastmodifieddate, alias, extras, interfacetype,foradapter) values('{"NoProxy":"true","ConnectionType":"ApiRequest","testDataset":{"name":"","attributes":{"bodyType":"raw","Endpoint":"","RequestMethod":"GET","Headers":[{"value":"application/json","key":"Content-Type"}],"LeapParams":[],"QueryParams":[],"Body":""}},"AuthDetails":{"password":"","authParams":{"grant_type":"","client_secret":"","client_id":""},"authToken":""},"AuthType":"NoAuth","Url":"https://api-aicloud.ad.infosys.com","fileId":"","tokenExpirationTime":""}','','9edc0833140044b022af7473766f2e9b533c55528d8214f105f64be0b5186a63','AIPA-CLD72732','leo1311',NULL,'REST','REST','2023-09-27 08:07:36','mohan.peta@ad.infosys.com','2023-09-27 08:07:37','AI-Cloud','{"apispec":{},"apispectemplate":{}}',NULL,1);
            insert into mldatasource (connectiondetails, description, dshashcode, name, organization, salt, type, category, activetime, lastmodifiedby, lastmodifieddate, alias, extras, interfacetype,foradapter) values('{"NoProxy":"true","ConnectionType":"ApiRequest","testDataset":{"name":"","attributes":{"bodyType":"raw","Endpoint":"","RequestMethod":"GET","Headers":"","LeapParams":[],"QueryParams":"","Body":""}},"AuthDetails":{"password":"","authParams":{"grant_type":"","client_secret":"","client_id":""},"authToken":""},"AuthType":"NoAuth","Url":"https://api-aicloud.ad.infosys.com","fileId":"","tokenExpirationTime":""}','','dd1dfe67c1893f14a6bde03fb7a9e8527c1263e83c7734630a57b6775ee15a9b','AIPACLD-12519','leo1311',NULL,'REST','REST','2023-07-26 13:32:58','admin','2023-07-26 13:32:58','AICloud-MLOps-Connection','{"apispec":{},"apispectemplate":{}}',NULL,1);